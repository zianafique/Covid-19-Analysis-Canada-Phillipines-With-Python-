{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xzFfvdEsM4q8",
    "outputId": "ad373459-4514-47c0-ea93-26fab7721740"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark-3.0.0-bin-hadoop2.7/\n",
      "spark-3.0.0-bin-hadoop2.7/NOTICE\n",
      "spark-3.0.0-bin-hadoop2.7/kubernetes/\n",
      "spark-3.0.0-bin-hadoop2.7/kubernetes/tests/\n",
      "spark-3.0.0-bin-hadoop2.7/kubernetes/tests/worker_memory_check.py\n",
      "spark-3.0.0-bin-hadoop2.7/kubernetes/tests/py_container_checks.py\n",
      "spark-3.0.0-bin-hadoop2.7/kubernetes/tests/pyfiles.py\n",
      "spark-3.0.0-bin-hadoop2.7/kubernetes/dockerfiles/\n",
      "spark-3.0.0-bin-hadoop2.7/kubernetes/dockerfiles/spark/\n",
      "spark-3.0.0-bin-hadoop2.7/kubernetes/dockerfiles/spark/entrypoint.sh\n",
      "spark-3.0.0-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/\n",
      "spark-3.0.0-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/R/\n",
      "spark-3.0.0-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/R/Dockerfile\n",
      "spark-3.0.0-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/python/\n",
      "spark-3.0.0-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/python/Dockerfile\n",
      "spark-3.0.0-bin-hadoop2.7/kubernetes/dockerfiles/spark/Dockerfile\n",
      "spark-3.0.0-bin-hadoop2.7/jars/\n",
      "spark-3.0.0-bin-hadoop2.7/jars/jackson-xc-1.9.13.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/commons-digester-1.8.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/api-util-1.0.0-M20.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/hive-vector-code-gen-2.3.7.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/derby-10.12.1.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/commons-beanutils-1.9.4.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/httpcore-4.4.12.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/hadoop-yarn-api-2.7.4.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/scala-library-2.12.10.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/parquet-format-2.4.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/kryo-shaded-4.0.2.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/xercesImpl-2.12.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/commons-logging-1.1.3.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/okio-1.15.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/commons-compiler-3.0.16.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/jdo-api-3.0.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/spire-macros_2.12-0.17.0-M1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/arrow-memory-0.15.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/JLargeArrays-1.5.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/jsp-api-2.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/logging-interceptor-3.12.6.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/javax.servlet-api-3.1.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/jcl-over-slf4j-1.7.30.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/hive-cli-2.3.7.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/apacheds-i18n-2.0.0-M15.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/parquet-common-1.10.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/stax-api-1.0.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/jackson-dataformat-yaml-2.10.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/algebra_2.12-2.0.0-M2.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/spark-catalyst_2.12-3.0.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/hadoop-annotations-2.7.4.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/guice-servlet-3.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/kubernetes-client-4.9.2.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/spire-util_2.12-0.17.0-M1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/jakarta.activation-api-1.2.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/spark-kubernetes_2.12-3.0.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/jline-2.14.6.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/breeze_2.12-1.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/metrics-jvm-4.1.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/machinist_2.12-0.6.8.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/scala-compiler-2.12.10.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/commons-pool-1.5.4.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/arrow-format-0.15.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/spark-kvstore_2.12-3.0.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/jta-1.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/istack-commons-runtime-3.0.8.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/metrics-graphite-4.1.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/hadoop-hdfs-2.7.4.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/commons-collections-3.2.2.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/audience-annotations-0.5.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/jpam-1.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/jakarta.annotation-api-1.3.5.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/spark-sql_2.12-3.0.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/xmlenc-0.52.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/api-asn1-api-1.0.0-M20.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/py4j-0.10.9.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/hadoop-mapreduce-client-common-2.7.4.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/spire-platform_2.12-0.17.0-M1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/avro-1.8.2.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/curator-client-2.7.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/antlr4-runtime-4.7.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/javax.inject-1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/jersey-media-jaxb-2.30.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/commons-lang3-3.9.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/univocity-parsers-2.8.3.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/javax.jdo-3.2.0-m3.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/hadoop-auth-2.7.4.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/commons-io-2.4.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/spark-tags_2.12-3.0.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/objenesis-2.5.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/paranamer-2.8.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/cats-kernel_2.12-2.0.0-M4.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/flatbuffers-java-1.9.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/jersey-server-2.30.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/stream-2.9.6.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/datanucleus-api-jdo-4.2.4.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/gson-2.2.4.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/xml-apis-1.4.01.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/apacheds-kerberos-codec-2.0.0-M15.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/hadoop-mapreduce-client-shuffle-2.7.4.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/hive-jdbc-2.3.7.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/spark-hive_2.12-3.0.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/hive-exec-2.3.7-core.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/spark-network-common_2.12-3.0.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/opencsv-2.3.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/avro-mapred-1.8.2-hadoop2.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/jsr305-3.0.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/macro-compat_2.12-1.1.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/spark-mesos_2.12-3.0.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/commons-dbcp-1.4.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/jersey-container-servlet-core-2.30.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/orc-core-1.5.10.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/hk2-api-2.6.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/parquet-jackson-1.10.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/mesos-1.4.0-shaded-protobuf.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/spark-streaming_2.12-3.0.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/chill-java-0.9.5.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/automaton-1.11-8.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/commons-lang-2.6.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/jackson-annotations-2.10.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/hk2-utils-2.6.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/velocity-1.5.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/htrace-core-3.1.0-incubating.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/jul-to-slf4j-1.7.30.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/JTransforms-3.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/json4s-ast_2.12-3.6.6.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/jersey-client-2.30.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/httpclient-4.5.6.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/spark-hive-thriftserver_2.12-3.0.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/jetty-sslengine-6.1.26.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/spark-graphx_2.12-3.0.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/spark-yarn_2.12-3.0.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/spire_2.12-0.17.0-M1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/jersey-hk2-2.30.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/commons-math3-3.4.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/xbean-asm7-shaded-4.15.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/jakarta.validation-api-2.0.2.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/parquet-encoding-1.10.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/slf4j-log4j12-1.7.30.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/hadoop-mapreduce-client-app-2.7.4.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/spark-mllib_2.12-3.0.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/zstd-jni-1.4.4-3.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/slf4j-api-1.7.30.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/commons-compress-1.8.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/spark-repl_2.12-3.0.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/hive-shims-0.23-2.3.7.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/guava-14.0.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/stax-api-1.0-2.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/zjsonpatch-0.3.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/hive-storage-api-2.7.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/shapeless_2.12-2.3.3.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/kubernetes-model-common-4.9.2.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/oro-2.0.8.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/hadoop-yarn-client-2.7.4.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/libfb303-0.9.3.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/core-1.1.2.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/jersey-container-servlet-2.30.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/datanucleus-rdbms-4.1.19.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/super-csv-2.2.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/compress-lzf-1.0.3.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/commons-crypto-1.0.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/jackson-module-paranamer-2.10.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/aopalliance-1.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/osgi-resource-locator-1.0.3.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/spark-unsafe_2.12-3.0.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/jackson-module-scala_2.12-2.10.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/hive-shims-2.3.7.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/hadoop-yarn-server-common-2.7.4.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/json-1.8.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/antlr-runtime-3.5.2.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/threeten-extra-1.5.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/jetty-6.1.26.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/jackson-module-jaxb-annotations-2.10.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/jersey-common-2.30.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/aircompressor-0.10.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/lz4-java-1.7.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/hadoop-client-2.7.4.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/activation-1.1.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/shims-0.7.45.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/libthrift-0.12.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/orc-mapreduce-1.5.10.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/HikariCP-2.5.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/generex-1.0.2.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/okhttp-3.12.6.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/snappy-java-1.1.7.5.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/breeze-macros_2.12-1.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/leveldbjni-all-1.8.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/jaxb-runtime-2.3.2.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/commons-httpclient-3.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/jackson-core-asl-1.9.13.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/scala-xml_2.12-1.2.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/hk2-locator-2.6.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/hadoop-common-2.7.4.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/curator-recipes-2.7.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/jackson-mapper-asl-1.9.13.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/hive-common-2.3.7.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/xz-1.5.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/ST4-4.0.4.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/hive-shims-scheduler-2.3.7.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/parquet-hadoop-1.10.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/chill_2.12-0.9.5.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/commons-configuration-1.6.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/jackson-databind-2.10.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/scala-reflect-2.12.10.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/joda-time-2.10.5.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/spark-network-shuffle_2.12-3.0.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/minlog-1.3.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/jakarta.ws.rs-api-2.1.6.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/orc-shims-1.5.10.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/aopalliance-repackaged-2.6.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/bonecp-0.8.0.RELEASE.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/jodd-core-3.5.2.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/hadoop-yarn-server-web-proxy-2.7.4.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/jackson-core-2.10.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/protobuf-java-2.5.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/commons-net-3.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/hadoop-mapreduce-client-jobclient-2.7.4.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/datanucleus-core-4.1.17.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/jackson-jaxrs-1.9.13.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/janino-3.0.16.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/spark-sketch_2.12-3.0.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/hive-shims-common-2.3.7.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/javolution-5.5.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/transaction-api-1.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/jackson-datatype-jsr310-2.10.3.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/spark-mllib-local_2.12-3.0.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/jaxb-api-2.2.2.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/commons-cli-1.2.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/jakarta.inject-2.6.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/metrics-jmx-4.1.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/arrow-vector-0.15.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/jakarta.xml.bind-api-2.3.2.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/commons-codec-1.10.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/hadoop-yarn-common-2.7.4.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/curator-framework-2.7.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/arpack_combined_all-0.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/hive-metastore-2.3.7.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/hive-beeline-2.3.7.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/metrics-core-4.1.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/hive-llap-common-2.3.7.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/netty-all-4.1.47.Final.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/javassist-3.25.0-GA.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/scala-collection-compat_2.12-2.1.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/parquet-column-1.10.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/jetty-util-6.1.26.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/kubernetes-model-4.9.2.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/avro-ipc-1.8.2.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/spark-core_2.12-3.0.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/guice-3.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/commons-text-1.6.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/json4s-scalap_2.12-3.6.6.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/metrics-json-4.1.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/snakeyaml-1.24.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/json4s-jackson_2.12-3.6.6.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/ivy-2.4.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/hadoop-mapreduce-client-core-2.7.4.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/json4s-core_2.12-3.6.6.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/spark-tags_2.12-3.0.0-tests.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/pyrolite-4.30.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/spark-launcher_2.12-3.0.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/log4j-1.2.17.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/hive-serde-2.3.7.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/scala-parser-combinators_2.12-1.1.2.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/RoaringBitmap-0.7.45.jar\n",
      "spark-3.0.0-bin-hadoop2.7/jars/zookeeper-3.4.14.jar\n",
      "spark-3.0.0-bin-hadoop2.7/data/\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/sample_lda_data.txt\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/sample_libsvm_data.txt\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/sample_svm_data.txt\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/sample_multiclass_classification_data.txt\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/sample_linear_regression_data.txt\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/sample_lda_libsvm_data.txt\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/sample_fpgrowth.txt\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/sample_binary_classification_data.txt\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/sample_isotonic_regression_libsvm_data.txt\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/iris_libsvm.txt\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/sample_movielens_data.txt\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/als/\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/als/test.data\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/als/sample_movielens_ratings.txt\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/sample_kmeans_data.txt\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/pic_data.txt\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/images/\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/images/origin/\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/images/origin/kittens/\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/images/origin/kittens/54893.jpg\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/images/origin/kittens/not-image.txt\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/images/origin/kittens/DP802813.jpg\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/images/origin/kittens/29.5.a_b_EGDP022204.jpg\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/images/origin/kittens/DP153539.jpg\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/images/origin/license.txt\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/images/origin/multi-channel/\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/images/origin/multi-channel/BGRA.png\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/images/origin/multi-channel/BGRA_alpha_60.png\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/images/origin/multi-channel/grayscale.jpg\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/images/origin/multi-channel/chr30.4.184.jpg\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/images/partitioned/\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-01/\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-01/BGRA.png\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-01/BGRA_alpha_60.png\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-02/\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-02/grayscale.jpg\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-02/chr30.4.184.jpg\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-01/\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-01/not-image.txt\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-01/29.5.a_b_EGDP022204.jpg\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/54893.jpg\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/DP802813.jpg\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/DP153539.jpg\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/images/license.txt\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/ridge-data/\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/ridge-data/lpsa.data\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/kmeans_data.txt\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/streaming_kmeans_data_test.txt\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/pagerank_data.txt\n",
      "spark-3.0.0-bin-hadoop2.7/data/mllib/gmm_data.txt\n",
      "spark-3.0.0-bin-hadoop2.7/data/graphx/\n",
      "spark-3.0.0-bin-hadoop2.7/data/graphx/users.txt\n",
      "spark-3.0.0-bin-hadoop2.7/data/graphx/followers.txt\n",
      "spark-3.0.0-bin-hadoop2.7/data/streaming/\n",
      "spark-3.0.0-bin-hadoop2.7/data/streaming/AFINN-111.txt\n",
      "spark-3.0.0-bin-hadoop2.7/R/\n",
      "spark-3.0.0-bin-hadoop2.7/R/lib/\n",
      "spark-3.0.0-bin-hadoop2.7/R/lib/sparkr.zip\n",
      "spark-3.0.0-bin-hadoop2.7/R/lib/SparkR/\n",
      "spark-3.0.0-bin-hadoop2.7/R/lib/SparkR/tests/\n",
      "spark-3.0.0-bin-hadoop2.7/R/lib/SparkR/tests/testthat/\n",
      "spark-3.0.0-bin-hadoop2.7/R/lib/SparkR/tests/testthat/test_basic.R\n",
      "spark-3.0.0-bin-hadoop2.7/R/lib/SparkR/DESCRIPTION\n",
      "spark-3.0.0-bin-hadoop2.7/R/lib/SparkR/profile/\n",
      "spark-3.0.0-bin-hadoop2.7/R/lib/SparkR/profile/shell.R\n",
      "spark-3.0.0-bin-hadoop2.7/R/lib/SparkR/profile/general.R\n",
      "spark-3.0.0-bin-hadoop2.7/R/lib/SparkR/INDEX\n",
      "spark-3.0.0-bin-hadoop2.7/R/lib/SparkR/Meta/\n",
      "spark-3.0.0-bin-hadoop2.7/R/lib/SparkR/Meta/features.rds\n",
      "spark-3.0.0-bin-hadoop2.7/R/lib/SparkR/Meta/links.rds\n",
      "spark-3.0.0-bin-hadoop2.7/R/lib/SparkR/Meta/nsInfo.rds\n",
      "spark-3.0.0-bin-hadoop2.7/R/lib/SparkR/Meta/package.rds\n",
      "spark-3.0.0-bin-hadoop2.7/R/lib/SparkR/Meta/vignette.rds\n",
      "spark-3.0.0-bin-hadoop2.7/R/lib/SparkR/Meta/Rd.rds\n",
      "spark-3.0.0-bin-hadoop2.7/R/lib/SparkR/Meta/hsearch.rds\n",
      "spark-3.0.0-bin-hadoop2.7/R/lib/SparkR/help/\n",
      "spark-3.0.0-bin-hadoop2.7/R/lib/SparkR/help/SparkR.rdb\n",
      "spark-3.0.0-bin-hadoop2.7/R/lib/SparkR/help/aliases.rds\n",
      "spark-3.0.0-bin-hadoop2.7/R/lib/SparkR/help/SparkR.rdx\n",
      "spark-3.0.0-bin-hadoop2.7/R/lib/SparkR/help/AnIndex\n",
      "spark-3.0.0-bin-hadoop2.7/R/lib/SparkR/help/paths.rds\n",
      "spark-3.0.0-bin-hadoop2.7/R/lib/SparkR/R/\n",
      "spark-3.0.0-bin-hadoop2.7/R/lib/SparkR/R/SparkR.rdb\n",
      "spark-3.0.0-bin-hadoop2.7/R/lib/SparkR/R/SparkR.rdx\n",
      "spark-3.0.0-bin-hadoop2.7/R/lib/SparkR/R/SparkR\n",
      "spark-3.0.0-bin-hadoop2.7/R/lib/SparkR/NAMESPACE\n",
      "spark-3.0.0-bin-hadoop2.7/R/lib/SparkR/doc/\n",
      "spark-3.0.0-bin-hadoop2.7/R/lib/SparkR/doc/sparkr-vignettes.Rmd\n",
      "spark-3.0.0-bin-hadoop2.7/R/lib/SparkR/doc/index.html\n",
      "spark-3.0.0-bin-hadoop2.7/R/lib/SparkR/doc/sparkr-vignettes.html\n",
      "spark-3.0.0-bin-hadoop2.7/R/lib/SparkR/doc/sparkr-vignettes.R\n",
      "spark-3.0.0-bin-hadoop2.7/R/lib/SparkR/html/\n",
      "spark-3.0.0-bin-hadoop2.7/R/lib/SparkR/html/00Index.html\n",
      "spark-3.0.0-bin-hadoop2.7/R/lib/SparkR/html/R.css\n",
      "spark-3.0.0-bin-hadoop2.7/R/lib/SparkR/worker/\n",
      "spark-3.0.0-bin-hadoop2.7/R/lib/SparkR/worker/worker.R\n",
      "spark-3.0.0-bin-hadoop2.7/R/lib/SparkR/worker/daemon.R\n",
      "spark-3.0.0-bin-hadoop2.7/README.md\n",
      "spark-3.0.0-bin-hadoop2.7/RELEASE\n",
      "spark-3.0.0-bin-hadoop2.7/yarn/\n",
      "spark-3.0.0-bin-hadoop2.7/yarn/spark-3.0.0-yarn-shuffle.jar\n",
      "spark-3.0.0-bin-hadoop2.7/LICENSE\n",
      "spark-3.0.0-bin-hadoop2.7/sbin/\n",
      "spark-3.0.0-bin-hadoop2.7/sbin/stop-mesos-shuffle-service.sh\n",
      "spark-3.0.0-bin-hadoop2.7/sbin/start-master.sh\n",
      "spark-3.0.0-bin-hadoop2.7/sbin/spark-config.sh\n",
      "spark-3.0.0-bin-hadoop2.7/sbin/start-history-server.sh\n",
      "spark-3.0.0-bin-hadoop2.7/sbin/start-slaves.sh\n",
      "spark-3.0.0-bin-hadoop2.7/sbin/spark-daemon.sh\n",
      "spark-3.0.0-bin-hadoop2.7/sbin/stop-mesos-dispatcher.sh\n",
      "spark-3.0.0-bin-hadoop2.7/sbin/start-mesos-shuffle-service.sh\n",
      "spark-3.0.0-bin-hadoop2.7/sbin/slaves.sh\n",
      "spark-3.0.0-bin-hadoop2.7/sbin/stop-history-server.sh\n",
      "spark-3.0.0-bin-hadoop2.7/sbin/start-thriftserver.sh\n",
      "spark-3.0.0-bin-hadoop2.7/sbin/stop-thriftserver.sh\n",
      "spark-3.0.0-bin-hadoop2.7/sbin/start-slave.sh\n",
      "spark-3.0.0-bin-hadoop2.7/sbin/start-all.sh\n",
      "spark-3.0.0-bin-hadoop2.7/sbin/stop-slave.sh\n",
      "spark-3.0.0-bin-hadoop2.7/sbin/spark-daemons.sh\n",
      "spark-3.0.0-bin-hadoop2.7/sbin/stop-slaves.sh\n",
      "spark-3.0.0-bin-hadoop2.7/sbin/stop-all.sh\n",
      "spark-3.0.0-bin-hadoop2.7/sbin/start-mesos-dispatcher.sh\n",
      "spark-3.0.0-bin-hadoop2.7/sbin/stop-master.sh\n",
      "spark-3.0.0-bin-hadoop2.7/examples/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/r/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/r/ml/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/r/ml/survreg.R\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/r/ml/glm.R\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/r/ml/prefixSpan.R\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/r/ml/powerIterationClustering.R\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/r/ml/lda.R\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/r/ml/kstest.R\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/r/ml/isoreg.R\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/r/ml/ml.R\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/r/ml/naiveBayes.R\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/r/ml/mlp.R\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/r/ml/als.R\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/r/ml/kmeans.R\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/r/ml/svmLinear.R\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/r/ml/logit.R\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/r/ml/randomForest.R\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/r/ml/gbt.R\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/r/ml/decisionTree.R\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/r/ml/gaussianMixture.R\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/r/ml/bisectingKmeans.R\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/r/ml/fpm.R\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/r/dataframe.R\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/r/RSparkSQLExample.R\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/r/data-manipulation.R\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/r/streaming/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/r/streaming/structured_network_wordcount.R\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/AccumulatorMetricsTest.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FMRegressorExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FMClassifierExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/SummarizerExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RobustScalerExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkRemoteFileTest.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/pythonconverters/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKerberizedKafkaWordCount.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/SimpleTypedAggregator.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/hive/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKerberizedKafkaWordCount.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedScalar.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/resources/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/resources/people.json\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/resources/users.avro\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/resources/people.csv\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/resources/users.parquet\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/resources/users.orc\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/resources/dir1/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/resources/dir1/file1.parquet\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/resources/dir1/dir2/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/resources/dir1/dir2/file2.parquet\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/resources/dir1/file3.json\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/resources/user.avsc\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/resources/full_user.avsc\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/resources/kv1.txt\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/resources/people.txt\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/resources/employees.json\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaSummarizerExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFMClassifierExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFMRegressorExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRobustScalerExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKerberizedKafkaWordCount.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedScalar.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/hive/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKerberizedKafkaWordCount.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaTC.java\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scripts/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/scripts/getGpusResources.sh\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/kmeans.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/dct_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/count_vectorizer_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/chisq_selector_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/tf_idf_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/cross_validator.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/linear_regression_with_elastic_net.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/normalizer_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/fm_regressor_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/polynomial_expansion_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/pipeline_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/generalized_linear_regression_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/multilayer_perceptron_classification.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/bisecting_k_means_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/chi_square_test_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/train_validation_split.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/stopwords_remover_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/linearsvc.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/lda_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/random_forest_regressor_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/vector_assembler_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/word2vec_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/string_indexer_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/decision_tree_classification_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/index_to_string_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/bucketizer_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/vector_size_hint_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/vector_indexer_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/tokenizer_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/robust_scaler_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/standard_scaler_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/kmeans_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/power_iteration_clustering_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/naive_bayes_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/pca_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/aft_survival_regression.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/min_max_scaler_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/elementwise_product_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/dataframe_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/n_gram_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/rformula_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/one_vs_rest_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/als_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/onehot_encoder_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/vector_slicer_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/logistic_regression_with_elastic_net.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/sql_transformer.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/summarizer_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/quantile_discretizer_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/feature_hasher_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/imputer_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/estimator_transformer_param_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/logistic_regression_summary_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/decision_tree_regression_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/fm_classifier_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/gaussian_mixture_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/fpgrowth_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/random_forest_classifier_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/correlation_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/min_hash_lsh_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/binarizer_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/prefixspan_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/max_abs_scaler_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/isotonic_regression_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/ml/interaction_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/logistic_regression.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/als.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/word2vec.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/correlations_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/gradient_boosting_classification_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/kernel_density_estimation_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/hypothesis_testing_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/svd_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/kmeans.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/tf_idf_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/correlations.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/random_forest_regression_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/normalizer_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/logistic_regression.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/multi_label_metrics_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/gradient_boosting_regression_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/random_forest_classification_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/streaming_linear_regression_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/sampled_rdds.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/bisecting_k_means_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/k_means_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/streaming_k_means_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/word2vec_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/multi_class_metrics_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/decision_tree_classification_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/summary_statistics_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/binary_classification_metrics_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/standard_scaler_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/power_iteration_clustering_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/gaussian_mixture_model.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/regression_metrics_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/naive_bayes_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/elementwise_product_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/linear_regression_with_sgd_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/pca_rowmatrix_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/random_rdd_generation.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/decision_tree_regression_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/gaussian_mixture_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/recommendation_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/fpgrowth_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/ranking_metrics_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/svm_with_sgd_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/isotonic_regression_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/mllib/stratified_sampling_example.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/wordcount.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/status_api_demo.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/pagerank.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/sort.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/transitive_closure.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/avro_inputformat.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/pi.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/streaming/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/streaming/queue_stream.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/streaming/stateful_network_wordcount.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/streaming/network_wordjoinsentiments.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/streaming/sql_network_wordcount.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/streaming/network_wordcount.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/streaming/hdfs_wordcount.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/streaming/recoverable_network_wordcount.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/sql/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/sql/datasource.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/sql/hive.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/sql/arrow.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/sql/streaming/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_network_wordcount.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/sql/basic.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/src/main/python/parquet_inputformat.py\n",
      "spark-3.0.0-bin-hadoop2.7/examples/jars/\n",
      "spark-3.0.0-bin-hadoop2.7/examples/jars/spark-examples_2.12-3.0.0.jar\n",
      "spark-3.0.0-bin-hadoop2.7/examples/jars/scopt_2.12-3.7.1.jar\n",
      "spark-3.0.0-bin-hadoop2.7/conf/\n",
      "spark-3.0.0-bin-hadoop2.7/conf/slaves.template\n",
      "spark-3.0.0-bin-hadoop2.7/conf/metrics.properties.template\n",
      "spark-3.0.0-bin-hadoop2.7/conf/fairscheduler.xml.template\n",
      "spark-3.0.0-bin-hadoop2.7/conf/log4j.properties.template\n",
      "spark-3.0.0-bin-hadoop2.7/conf/spark-defaults.conf.template\n",
      "spark-3.0.0-bin-hadoop2.7/conf/spark-env.sh.template\n",
      "spark-3.0.0-bin-hadoop2.7/bin/\n",
      "spark-3.0.0-bin-hadoop2.7/bin/sparkR.cmd\n",
      "spark-3.0.0-bin-hadoop2.7/bin/sparkR\n",
      "spark-3.0.0-bin-hadoop2.7/bin/spark-submit\n",
      "spark-3.0.0-bin-hadoop2.7/bin/pyspark2.cmd\n",
      "spark-3.0.0-bin-hadoop2.7/bin/spark-class\n",
      "spark-3.0.0-bin-hadoop2.7/bin/pyspark.cmd\n",
      "spark-3.0.0-bin-hadoop2.7/bin/spark-submit2.cmd\n",
      "spark-3.0.0-bin-hadoop2.7/bin/load-spark-env.cmd\n",
      "spark-3.0.0-bin-hadoop2.7/bin/spark-sql\n",
      "spark-3.0.0-bin-hadoop2.7/bin/docker-image-tool.sh\n",
      "spark-3.0.0-bin-hadoop2.7/bin/find-spark-home.cmd\n",
      "spark-3.0.0-bin-hadoop2.7/bin/load-spark-env.sh\n",
      "spark-3.0.0-bin-hadoop2.7/bin/pyspark\n",
      "spark-3.0.0-bin-hadoop2.7/bin/spark-shell.cmd\n",
      "spark-3.0.0-bin-hadoop2.7/bin/spark-shell2.cmd\n",
      "spark-3.0.0-bin-hadoop2.7/bin/spark-submit.cmd\n",
      "spark-3.0.0-bin-hadoop2.7/bin/beeline.cmd\n",
      "spark-3.0.0-bin-hadoop2.7/bin/find-spark-home\n",
      "spark-3.0.0-bin-hadoop2.7/bin/spark-class.cmd\n",
      "spark-3.0.0-bin-hadoop2.7/bin/sparkR2.cmd\n",
      "spark-3.0.0-bin-hadoop2.7/bin/beeline\n",
      "spark-3.0.0-bin-hadoop2.7/bin/spark-class2.cmd\n",
      "spark-3.0.0-bin-hadoop2.7/bin/spark-sql.cmd\n",
      "spark-3.0.0-bin-hadoop2.7/bin/run-example\n",
      "spark-3.0.0-bin-hadoop2.7/bin/spark-shell\n",
      "spark-3.0.0-bin-hadoop2.7/bin/run-example.cmd\n",
      "spark-3.0.0-bin-hadoop2.7/bin/spark-sql2.cmd\n",
      "spark-3.0.0-bin-hadoop2.7/python/\n",
      "spark-3.0.0-bin-hadoop2.7/python/.gitignore\n",
      "spark-3.0.0-bin-hadoop2.7/python/run-tests-with-coverage\n",
      "spark-3.0.0-bin-hadoop2.7/python/pylintrc\n",
      "spark-3.0.0-bin-hadoop2.7/python/MANIFEST.in\n",
      "spark-3.0.0-bin-hadoop2.7/python/README.md\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_coverage/\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_coverage/coverage_daemon.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_coverage/conf/\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_coverage/conf/spark-defaults.conf\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_coverage/sitecustomize.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/run-tests.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/setup.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/userlibrary.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/hello/\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/hello/sub_hello/\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/hello/sub_hello/sub_hello.txt\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/hello/hello.txt\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/userlib-0.1.zip\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/SimpleHTTPServer.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/people.json\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/people_array.json\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/people_array_utf16le.json\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/text-test.txt\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/ages.csv\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/.part-r-00005.gz.parquet.crc\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/part-r-00005.gz.parquet\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00002.gz.parquet.crc\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00004.gz.parquet.crc\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00004.gz.parquet\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00002.gz.parquet\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/.part-r-00007.gz.parquet.crc\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/part-r-00007.gz.parquet\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_metadata\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/.part-r-00008.gz.parquet.crc\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/part-r-00008.gz.parquet\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_common_metadata\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_SUCCESS\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/_SUCCESS\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/ages_newlines.csv\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/streaming/\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/streaming/text-test.txt\n",
      "spark-3.0.0-bin-hadoop2.7/python/test_support/sql/people1.json\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/tests/\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/tests/test_rddbarrier.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/tests/test_worker.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/tests/test_serializers.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/tests/test_util.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/tests/test_rdd.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/tests/__init__.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/tests/test_broadcast.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/tests/test_appsubmit.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/tests/test_profiler.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/tests/test_pin_thread.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/tests/test_shuffle.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/tests/test_join.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/tests/test_taskcontext.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/tests/test_context.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/tests/test_readwrite.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/tests/test_conf.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/tests/test_daemon.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/testing/\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/testing/mlutils.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/testing/__init__.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/testing/mllibutils.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/testing/utils.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/testing/sqlutils.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/testing/streamingutils.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/accumulators.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/rddsampler.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/ml/\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/ml/tests/\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/ml/tests/test_algorithms.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/ml/tests/test_evaluation.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/ml/tests/test_feature.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/ml/tests/test_pipeline.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/ml/tests/test_wrapper.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/ml/tests/__init__.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/ml/tests/test_tuning.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/ml/tests/test_persistence.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/ml/tests/test_param.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/ml/tests/test_training_summary.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/ml/tests/test_linalg.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/ml/tests/test_image.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/ml/tests/test_stat.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/ml/tests/test_base.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/ml/functions.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/ml/tuning.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/ml/pipeline.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/ml/base.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/ml/feature.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/ml/__init__.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/ml/stat.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/ml/image.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/ml/classification.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/ml/recommendation.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/ml/regression.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/ml/param/\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/ml/param/_shared_params_code_gen.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/ml/param/__init__.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/ml/param/shared.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/ml/tree.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/ml/fpm.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/ml/wrapper.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/ml/clustering.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/ml/common.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/ml/linalg/\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/ml/linalg/__init__.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/ml/evaluation.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/ml/util.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/find_spark_home.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/heapq3.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/serializers.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/java_gateway.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/traceback_utils.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/conf.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/__init__.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/mllib/\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/mllib/tests/\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/mllib/tests/test_algorithms.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/mllib/tests/test_streaming_algorithms.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/mllib/tests/test_util.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/mllib/tests/test_feature.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/mllib/tests/__init__.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/mllib/tests/test_linalg.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/mllib/tests/test_stat.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/mllib/feature.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/mllib/__init__.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/mllib/recommendation.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/mllib/regression.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/mllib/tree.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/mllib/fpm.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/mllib/random.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/mllib/stat/\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/mllib/stat/distribution.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/mllib/stat/__init__.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/mllib/stat/KernelDensity.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/mllib/stat/test.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/mllib/stat/_statistics.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/mllib/clustering.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/mllib/common.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/mllib/linalg/\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/mllib/linalg/__init__.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/mllib/linalg/distributed.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/mllib/evaluation.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/mllib/util.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/resultiterable.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/profiler.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/statcounter.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/join.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/daemon.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/rdd.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/context.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/cloudpickle.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/version.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/resource.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/files.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/worker.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/shell.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/streaming/\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/streaming/tests/\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/streaming/tests/test_listener.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/streaming/tests/test_kinesis.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/streaming/tests/__init__.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/streaming/tests/test_dstream.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/streaming/tests/test_context.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/streaming/dstream.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/streaming/__init__.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/streaming/kinesis.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/streaming/listener.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/streaming/context.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/streaming/util.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/status.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/tests/\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/tests/test_functions.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/tests/test_readwriter.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/tests/test_utils.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_grouped_map.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/tests/test_dataframe.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_map.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/tests/test_udf.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/tests/test_streaming.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/tests/__init__.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/tests/test_serde.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf_window.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/tests/test_group.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_cogrouped_map.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf_grouped_agg.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf_scalar.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/tests/test_catalog.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/tests/test_datasources.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf_typehints.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/tests/test_types.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/tests/test_column.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/tests/test_context.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/tests/test_conf.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/tests/test_arrow.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/tests/test_session.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/pandas/\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/pandas/functions.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/pandas/serializers.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/pandas/__init__.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/pandas/typehints.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/pandas/map_ops.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/pandas/types.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/pandas/group_ops.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/pandas/utils.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/pandas/conversion.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/functions.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/readwriter.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/catalog.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/window.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/udf.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/conf.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/__init__.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/session.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/column.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/group.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/context.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/types.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/dataframe.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/avro/\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/avro/functions.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/avro/__init__.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/utils.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/streaming.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/python/\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/python/pyspark/\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/python/pyspark/shell.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/shuffle.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/taskcontext.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/_globals.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/broadcast.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/util.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark/storagelevel.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/.coveragerc\n",
      "spark-3.0.0-bin-hadoop2.7/python/docs/\n",
      "spark-3.0.0-bin-hadoop2.7/python/docs/index.rst\n",
      "spark-3.0.0-bin-hadoop2.7/python/docs/conf.py\n",
      "spark-3.0.0-bin-hadoop2.7/python/docs/pyspark.ml.rst\n",
      "spark-3.0.0-bin-hadoop2.7/python/docs/pyspark.rst\n",
      "spark-3.0.0-bin-hadoop2.7/python/docs/_templates/\n",
      "spark-3.0.0-bin-hadoop2.7/python/docs/_templates/layout.html\n",
      "spark-3.0.0-bin-hadoop2.7/python/docs/_static/\n",
      "spark-3.0.0-bin-hadoop2.7/python/docs/_static/pyspark.css\n",
      "spark-3.0.0-bin-hadoop2.7/python/docs/_static/copybutton.js\n",
      "spark-3.0.0-bin-hadoop2.7/python/docs/_static/pyspark.js\n",
      "spark-3.0.0-bin-hadoop2.7/python/docs/pyspark.mllib.rst\n",
      "spark-3.0.0-bin-hadoop2.7/python/docs/make2.bat\n",
      "spark-3.0.0-bin-hadoop2.7/python/docs/pyspark.streaming.rst\n",
      "spark-3.0.0-bin-hadoop2.7/python/docs/pyspark.sql.rst\n",
      "spark-3.0.0-bin-hadoop2.7/python/docs/make.bat\n",
      "spark-3.0.0-bin-hadoop2.7/python/docs/Makefile\n",
      "spark-3.0.0-bin-hadoop2.7/python/docs/pyspark.resource.rst\n",
      "spark-3.0.0-bin-hadoop2.7/python/lib/\n",
      "spark-3.0.0-bin-hadoop2.7/python/lib/PY4J_LICENSE.txt\n",
      "spark-3.0.0-bin-hadoop2.7/python/lib/py4j-0.10.9-src.zip\n",
      "spark-3.0.0-bin-hadoop2.7/python/lib/pyspark.zip\n",
      "spark-3.0.0-bin-hadoop2.7/python/run-tests\n",
      "spark-3.0.0-bin-hadoop2.7/python/setup.cfg\n",
      "spark-3.0.0-bin-hadoop2.7/python/dist/\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark.egg-info/\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark.egg-info/dependency_links.txt\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark.egg-info/PKG-INFO\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark.egg-info/top_level.txt\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark.egg-info/requires.txt\n",
      "spark-3.0.0-bin-hadoop2.7/python/pyspark.egg-info/SOURCES.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-respond.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-sbt-launch-lib.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-antlr.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-dagre-d3.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-pyrolite.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-sorttable.js.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-janino.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-protobuf.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-jquery.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-scopt.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-netlib.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-d3.min.js.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-graphlib-dot.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-AnchorJS.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-datatables.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-pmml-model.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-paranamer.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-jakarta-ws-rs-api\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-dnsjava.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-jakarta.xml.bind-api.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-jakarta-annotation-api\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-CC0.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-jodd.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-f2j.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-heapq.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-machinist.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-javolution.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-modernizr.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-spire.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-leveldbjni.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-join.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-zstd-jni.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-slf4j.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-arpack.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-jsp-api.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-JTransforms.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-JLargeArrays.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-bootstrap.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-reflectasm.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-javassist.html\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-zstd.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-json-formatter.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-matchMedia-polyfill.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-scala.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-jakarta.activation-api.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-automaton.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-javax-transaction-transaction-api.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-jaxb-runtime.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-minlog.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-mustache.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-xmlenc.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-jline.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-istack-commons-runtime.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-py4j.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-vis-timeline.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-re2j.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-kryo.txt\n",
      "spark-3.0.0-bin-hadoop2.7/licenses/LICENSE-cloudpickle.txt\n"
     ]
    }
   ],
   "source": [
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "!wget -q https://downloads.apache.org/spark/spark-3.0.0/spark-3.0.0-bin-hadoop2.7.tgz\n",
    "!tar -xvf spark-3.0.0-bin-hadoop2.7.tgz\n",
    "!pip install -q findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "53LWfxYf5pit"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop2.7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zy3FfhKi5sgX"
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U-KO732m5vln"
   },
   "outputs": [],
   "source": [
    "spark= SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"ReadandWrite\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "id": "d3GopVzV52d5",
    "outputId": "dfd7ea14-577d-44a9-da8d-50cb1956f334"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.driver.port', '35873'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.master', 'local[*]'),\n",
       " ('spark.app.id', 'local-1596630504001'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.app.name', 'ReadandWrite'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.driver.host', '1972d410bedf'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 79,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "id": "hjy_8aEn55Sf",
    "outputId": "fae57023-81c7-4561-cecc-ebe0ed83d337"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://1972d410bedf:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>ReadandWrite</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fb64298b940>"
      ]
     },
     "execution_count": 80,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4H8a3i2r572s"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "path = \"/content/Case_Information.csv\"\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "id": "ohxtryYq8rKB",
    "outputId": "3747117f-4dbf-4b53-b11d-4e914d31c1ed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>age</th>\n",
       "      <th>age_group</th>\n",
       "      <th>sex</th>\n",
       "      <th>date_announced</th>\n",
       "      <th>date_recovered</th>\n",
       "      <th>date_of_death</th>\n",
       "      <th>status</th>\n",
       "      <th>date_announced_as_removed</th>\n",
       "      <th>province</th>\n",
       "      <th>muni_city</th>\n",
       "      <th>health_status</th>\n",
       "      <th>home_quarantined</th>\n",
       "      <th>date_of_onset_of_symptoms</th>\n",
       "      <th>pregnant</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C404174</td>\n",
       "      <td>38.0</td>\n",
       "      <td>35 to 39</td>\n",
       "      <td>Female</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recovered</td>\n",
       "      <td>2020-02-07</td>\n",
       "      <td>Negros Oriental</td>\n",
       "      <td>Dumaguete City</td>\n",
       "      <td>Recovered</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Central Visayas (Region VII)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C462688</td>\n",
       "      <td>44.0</td>\n",
       "      <td>40 to 44</td>\n",
       "      <td>Male</td>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>Died</td>\n",
       "      <td>2020-02-02</td>\n",
       "      <td>Negros Oriental</td>\n",
       "      <td>Dumaguete City</td>\n",
       "      <td>Died</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Central Visayas (Region VII)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C387710</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60 to 64</td>\n",
       "      <td>Female</td>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recovered</td>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>Bohol</td>\n",
       "      <td>Panglao</td>\n",
       "      <td>Recovered</td>\n",
       "      <td>No</td>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Central Visayas (Region VII)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C377460</td>\n",
       "      <td>48.0</td>\n",
       "      <td>45 to 49</td>\n",
       "      <td>Male</td>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recovered</td>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>Metropolitan Manila</td>\n",
       "      <td>Taguig</td>\n",
       "      <td>Recovered</td>\n",
       "      <td>No</td>\n",
       "      <td>2020-03-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Metropolitan Manila</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C498051</td>\n",
       "      <td>62.0</td>\n",
       "      <td>60 to 64</td>\n",
       "      <td>Male</td>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>Died</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>Rizal</td>\n",
       "      <td>Cainta</td>\n",
       "      <td>Died</td>\n",
       "      <td>No</td>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CALABARZON (Region IV-A)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   case_id   age  ... pregnant                        region\n",
       "0  C404174  38.0  ...      NaN  Central Visayas (Region VII)\n",
       "1  C462688  44.0  ...      NaN  Central Visayas (Region VII)\n",
       "2  C387710  60.0  ...      NaN  Central Visayas (Region VII)\n",
       "3  C377460  48.0  ...      NaN           Metropolitan Manila\n",
       "4  C498051  62.0  ...      NaN      CALABARZON (Region IV-A)\n",
       "\n",
       "[5 rows x 16 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "z_XIVUIfgpC6",
    "outputId": "cc761f47-1073-4fab-b8a2-aeaacca69105"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "case_id                      12091\n",
       "age                          12070\n",
       "age_group                    12070\n",
       "sex                          12091\n",
       "date_announced               12091\n",
       "date_recovered                1237\n",
       "date_of_death                  657\n",
       "status                       12091\n",
       "date_announced_as_removed     3266\n",
       "province                     11053\n",
       "muni_city                    11053\n",
       "health_status                12091\n",
       "home_quarantined              5310\n",
       "date_of_onset_of_symptoms     6561\n",
       "pregnant                      1925\n",
       "region                       11053\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6ETUTFE9nIJ"
   },
   "source": [
    "What do we want to find from this dataset?\n",
    "1. Philippine has recorded Southeast Asia's biggest daily jump in coronavirus deaths in the month of June. Why?\n",
    "2. Which age group is the most affected with Covid-19?\n",
    "3. Which age group has the highest risk of death when affected with covid-19?\n",
    "4. Covid-19 in the Philippine has reduced in April but increased again in May. Which province in the Philippine has led to the increased number of cases in the Philippine?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xri5GgkIViaO"
   },
   "source": [
    "Check Data type for all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "E8dTpwVe9day",
    "outputId": "cdbeff0e-d0d8-4be4-ac0e-3f07b83480e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "case_id                       object\n",
       "age                          float64\n",
       "age_group                     object\n",
       "sex                           object\n",
       "date_announced                object\n",
       "date_recovered                object\n",
       "date_of_death                 object\n",
       "status                        object\n",
       "date_announced_as_removed     object\n",
       "province                      object\n",
       "muni_city                     object\n",
       "health_status                 object\n",
       "home_quarantined              object\n",
       "date_of_onset_of_symptoms     object\n",
       "pregnant                      object\n",
       "region                        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ph4D63dOVmek"
   },
   "source": [
    "Change data type to the correct data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "t8rHLJ36-mIm",
    "outputId": "0792c159-1bae-4d72-e54e-b29daea16607"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "case_id                            category\n",
       "age                                 float64\n",
       "age_group                          category\n",
       "sex                                category\n",
       "date_announced               datetime64[ns]\n",
       "date_recovered               datetime64[ns]\n",
       "date_of_death                datetime64[ns]\n",
       "status                             category\n",
       "date_announced_as_removed    datetime64[ns]\n",
       "province                           category\n",
       "muni_city                          category\n",
       "health_status                      category\n",
       "home_quarantined                   category\n",
       "date_of_onset_of_symptoms    datetime64[ns]\n",
       "pregnant                           category\n",
       "region                             category\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['date_announced']= pd.to_datetime(df['date_announced'])\n",
    "df['date_recovered']= pd.to_datetime(df['date_recovered'])\n",
    "df['date_of_death']= pd.to_datetime(df['date_of_death'])\n",
    "df['date_announced_as_removed']= pd.to_datetime(df['date_announced_as_removed'])\n",
    "df['date_of_onset_of_symptoms']= pd.to_datetime(df['date_of_onset_of_symptoms'])\n",
    "df['case_id'] = df['case_id'].astype('category')\n",
    "df['age_group'] = df['age_group'].astype('category')\n",
    "df['sex'] = df['sex'].astype('category')\n",
    "df['status'] = df['status'].astype('category')\n",
    "df['province'] = df['province'].astype('category')\n",
    "df['muni_city'] = df['muni_city'].astype('category')\n",
    "df['health_status'] = df['health_status'].astype('category')\n",
    "df['home_quarantined'] = df['home_quarantined'].astype('category')\n",
    "df['pregnant'] = df['pregnant'].astype('category')\n",
    "df['region'] = df['region'].astype('category')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fSfikruqVsv8"
   },
   "source": [
    "Check the list of all columns in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "cqvC8hybow1O",
    "outputId": "5965517e-91af-4bea-ecab-b59430d18bd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['case_id', 'age', 'age_group', 'sex', 'date_announced',\n",
      "       'date_recovered', 'date_of_death', 'status',\n",
      "       'date_announced_as_removed', 'province', 'muni_city', 'health_status',\n",
      "       'home_quarantined', 'date_of_onset_of_symptoms', 'pregnant', 'region'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7vqtPailCQxn"
   },
   "source": [
    "Drop the column that has the same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d8k5xsK7CWkS"
   },
   "outputs": [],
   "source": [
    "df.drop('health_status', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XzroOr3HVyrt"
   },
   "source": [
    "Check the list of all columns in the dataset after drop the health_status column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "DWgmkkZdqG-d",
    "outputId": "142f236c-b739-4c10-8f70-c9befe30cdd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['case_id', 'age', 'age_group', 'sex', 'date_announced',\n",
      "       'date_recovered', 'date_of_death', 'status',\n",
      "       'date_announced_as_removed', 'province', 'muni_city',\n",
      "       'home_quarantined', 'date_of_onset_of_symptoms', 'pregnant', 'region'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "id": "pRuVxOITSNUN",
    "outputId": "6e046e5d-0e4d-4bbb-cfe7-eeb7ef9cedfb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>age</th>\n",
       "      <th>age_group</th>\n",
       "      <th>sex</th>\n",
       "      <th>date_announced</th>\n",
       "      <th>date_recovered</th>\n",
       "      <th>date_of_death</th>\n",
       "      <th>status</th>\n",
       "      <th>date_announced_as_removed</th>\n",
       "      <th>province</th>\n",
       "      <th>muni_city</th>\n",
       "      <th>home_quarantined</th>\n",
       "      <th>date_of_onset_of_symptoms</th>\n",
       "      <th>pregnant</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C404174</td>\n",
       "      <td>38.0</td>\n",
       "      <td>35 to 39</td>\n",
       "      <td>Female</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Recovered</td>\n",
       "      <td>2020-02-07</td>\n",
       "      <td>Negros Oriental</td>\n",
       "      <td>Dumaguete City</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Central Visayas (Region VII)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C462688</td>\n",
       "      <td>44.0</td>\n",
       "      <td>40 to 44</td>\n",
       "      <td>Male</td>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>Died</td>\n",
       "      <td>2020-02-02</td>\n",
       "      <td>Negros Oriental</td>\n",
       "      <td>Dumaguete City</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Central Visayas (Region VII)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C387710</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60 to 64</td>\n",
       "      <td>Female</td>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Recovered</td>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>Bohol</td>\n",
       "      <td>Panglao</td>\n",
       "      <td>No</td>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Central Visayas (Region VII)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C377460</td>\n",
       "      <td>48.0</td>\n",
       "      <td>45 to 49</td>\n",
       "      <td>Male</td>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Recovered</td>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>Metropolitan Manila</td>\n",
       "      <td>Taguig</td>\n",
       "      <td>No</td>\n",
       "      <td>2020-03-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Metropolitan Manila</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C498051</td>\n",
       "      <td>62.0</td>\n",
       "      <td>60 to 64</td>\n",
       "      <td>Male</td>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>Died</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>Rizal</td>\n",
       "      <td>Cainta</td>\n",
       "      <td>No</td>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CALABARZON (Region IV-A)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   case_id   age  ... pregnant                        region\n",
       "0  C404174  38.0  ...      NaN  Central Visayas (Region VII)\n",
       "1  C462688  44.0  ...      NaN  Central Visayas (Region VII)\n",
       "2  C387710  60.0  ...      NaN  Central Visayas (Region VII)\n",
       "3  C377460  48.0  ...      NaN           Metropolitan Manila\n",
       "4  C498051  62.0  ...      NaN      CALABARZON (Region IV-A)\n",
       "\n",
       "[5 rows x 15 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qSdFb6FVFNE6"
   },
   "source": [
    "Philippine has recorded Southeast Asia's biggest daily jump in coronavirus deaths in the month of June. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dj0AGcU0V9K9"
   },
   "source": [
    "Select two columns : date_announced and home_quarantined to do the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i8ZGUKteFctP"
   },
   "outputs": [],
   "source": [
    "data1 = df[['date_announced', 'home_quarantined']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "poYsJJA2bxZK"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "G_UanXf3ILOj",
    "outputId": "24c67994-3736-47ae-d704-4f4593bbe9ad"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_announced</th>\n",
       "      <th>home_quarantined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12086</th>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12087</th>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12088</th>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12089</th>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12090</th>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12091 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      date_announced home_quarantined\n",
       "0         2020-01-30              NaN\n",
       "1         2020-02-03              NaN\n",
       "2         2020-02-05               No\n",
       "3         2020-03-06               No\n",
       "4         2020-03-06               No\n",
       "...              ...              ...\n",
       "12086     2020-05-15              NaN\n",
       "12087     2020-05-15              NaN\n",
       "12088     2020-05-15              NaN\n",
       "12089     2020-05-15              Yes\n",
       "12090     2020-05-15              NaN\n",
       "\n",
       "[12091 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9qjAeuQN__f"
   },
   "source": [
    "Drop rows that have NAN values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "-Q2i_DKVJcwx",
    "outputId": "083c7d41-10cd-4283-b9d9-caeab661c79e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_announced</th>\n",
       "      <th>home_quarantined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-08</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5305</th>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5306</th>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5307</th>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5308</th>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5309</th>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5310 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     date_announced home_quarantined\n",
       "0        2020-02-05               No\n",
       "1        2020-03-06               No\n",
       "2        2020-03-06               No\n",
       "3        2020-03-07               No\n",
       "4        2020-03-08               No\n",
       "...             ...              ...\n",
       "5305     2020-05-15              Yes\n",
       "5306     2020-05-15              Yes\n",
       "5307     2020-05-15              Yes\n",
       "5308     2020-05-15              Yes\n",
       "5309     2020-05-15              Yes\n",
       "\n",
       "[5310 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1= data1.dropna()\n",
    "data1= data1.reset_index(drop=True)\n",
    "data1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QrGYhZhefmIe"
   },
   "source": [
    "To separate and count Yes and No data from home_quarantined column\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "FMcsG4PsXsms",
    "outputId": "1937bdab-0691-495c-bac8-fe0e69448197"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_announced</th>\n",
       "      <th>home_quarantined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3400</td>\n",
       "      <td>3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2020-03-31 00:00:00</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>225</td>\n",
       "      <td>3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>2020-03-08 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>2020-05-15 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date_announced home_quarantined\n",
       "count                  3400             3400\n",
       "unique                   69                1\n",
       "top     2020-03-31 00:00:00              Yes\n",
       "freq                    225             3400\n",
       "first   2020-03-08 00:00:00              NaN\n",
       "last    2020-05-15 00:00:00              NaN"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1[data1.home_quarantined == 'Yes'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_DUkGAXzWJTJ"
   },
   "source": [
    "Count 'Yes' data from home_quarantined column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "fsEGZoXKZB0l",
    "outputId": "6df0702d-009a-492c-d345-f0dd93cbc37a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_announced      3400\n",
       "home_quarantined    3400\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quarantined_yes = data1[data1.home_quarantined == 'Yes'].count()\n",
    "quarantined_yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8qli1-v4WOyD"
   },
   "source": [
    "Count 'No' data from home_quarantined column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "6rLt9H90X4Nm",
    "outputId": "beae3afe-16cd-42f6-ec6b-f34418c3b4c0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_announced</th>\n",
       "      <th>home_quarantined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1910</td>\n",
       "      <td>1910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2020-03-31 00:00:00</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>218</td>\n",
       "      <td>1910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>2020-02-05 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>2020-05-13 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date_announced home_quarantined\n",
       "count                  1910             1910\n",
       "unique                   67                1\n",
       "top     2020-03-31 00:00:00               No\n",
       "freq                    218             1910\n",
       "first   2020-02-05 00:00:00              NaN\n",
       "last    2020-05-13 00:00:00              NaN"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1[data1.home_quarantined == 'No'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "JHWSVi8EZawS",
    "outputId": "e576e463-b921-40d0-adfe-5d671d1a0383"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_announced      1910\n",
       "home_quarantined    1910\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quarantined_no = data1[data1.home_quarantined == 'No'].count()\n",
    "quarantined_no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NMDtEha3f0Wx"
   },
   "source": [
    "Using formula to calculate the percentage of Yes and No for people quarantine at home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "FQMF-u6kZ5L_",
    "outputId": "bad258c3-2d5b-4496-eb49-3c60dd99000a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_announced      64.0\n",
       "home_quarantined    64.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = quarantined_yes + quarantined_no\n",
    "yes_percentage = round((quarantined_yes / total)*100)\n",
    "yes_percentage \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "QDBYRWCEcm7S",
    "outputId": "0db8887f-9dd3-4497-9b76-a8612afe7b07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_announced      36.0\n",
       "home_quarantined    36.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_percentage = 100 - yes_percentage\n",
    "no_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJ91vbI9f_Ua"
   },
   "source": [
    "Using pie chart to calculate the percentage of Yes and No for people quarantine at home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "-G2sXktAb8TW",
    "outputId": "d6176527-8c43-4235-f4bb-a09098ccdb17"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "quarantined_no, quarantined_yes = 3400, 1910\n",
    "fig, ax = plt.subplots()\n",
    "ax.pie((quarantined_no, quarantined_yes), labels=('Yes', 'No'), autopct='%1.1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MkdbGukEOEpq"
   },
   "source": [
    "Extract month from date_announced column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "cy1T4OyWLiC7",
    "outputId": "b7bbd013-7a0f-4e15-e0e7-421343989b00"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_announced</th>\n",
       "      <th>home_quarantined</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-08</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5305</th>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5306</th>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5307</th>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5308</th>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5309</th>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5310 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     date_announced home_quarantined  month\n",
       "0        2020-02-05               No      2\n",
       "1        2020-03-06               No      3\n",
       "2        2020-03-06               No      3\n",
       "3        2020-03-07               No      3\n",
       "4        2020-03-08               No      3\n",
       "...             ...              ...    ...\n",
       "5305     2020-05-15              Yes      5\n",
       "5306     2020-05-15              Yes      5\n",
       "5307     2020-05-15              Yes      5\n",
       "5308     2020-05-15              Yes      5\n",
       "5309     2020-05-15              Yes      5\n",
       "\n",
       "[5310 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1['month'] = pd.DatetimeIndex(data1['date_announced']).month\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "WxjAebYi47wc",
    "outputId": "9c1f96df-1c30-409a-d1f5-62cfa5afc1d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_announced      datetime64[ns]\n",
       "home_quarantined          category\n",
       "month                        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rBXF0Z18WYnR"
   },
   "source": [
    "Group the data by month acolumn and home_quarantined column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "id": "A6ky-WfrXzW0",
    "outputId": "733cfb0a-5ead-4270-ba02-35c51493ec1d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month  home_quarantined\n",
       "2      No                     1\n",
       "       Yes                    0\n",
       "3      No                   865\n",
       "       Yes                  946\n",
       "4      No                  1003\n",
       "       Yes                 2098\n",
       "5      No                    41\n",
       "       Yes                  356\n",
       "Name: date_announced, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1_test = data1.groupby([\"month\", \"home_quarantined\"])[\"date_announced\"].size()\n",
    "data1_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QB1I4hQNaNk2"
   },
   "source": [
    "Unstack the data from home_quarantined column to separate 'Yes' and 'No' into two differents new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "JREu2_W43yq8",
    "outputId": "fb0dd7b9-11c4-4053-c605-c5fb555725c6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>home_quarantined</th>\n",
       "      <th>No</th>\n",
       "      <th>Yes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>865</td>\n",
       "      <td>946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1003</td>\n",
       "      <td>2098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>41</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "home_quarantined    No   Yes\n",
       "month                       \n",
       "2                    1     0\n",
       "3                  865   946\n",
       "4                 1003  2098\n",
       "5                   41   356"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1_test1 = data1_test.unstack()\n",
    "data1_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "id": "u00h_zhHfWpM",
    "outputId": "8c75f9a9-0513-4c4a-821e-c7e786eb07c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb64018f278>"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6sAAAF/CAYAAACv0l+VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de7hdVXk37N8DQWgBASVSJEjQAnI0YuSgpUWwgHwq6lUVigJWQRTqobafiu0bbEurLS1VtCAWRCgeUKRQxSpVQLGiBMwXOYgECRIaIYCCgBxCxvfHmsm7CAk57J3smZ37vq517bXGHHPOZ669N+S3x5hjVWstAAAA0CfrjHUBAAAAsDhhFQAAgN4RVgEAAOgdYRUAAIDeEVYBAADoHWEVAACA3hFWARhTVdWq6nd7UMf1VbXvWNcx2qrq7Kr62zE6d1XVZ6rql1X1w7GoYXFVdVRVXTnWdQCwbMIqAEmSqppdVY9W1eaLtf+oC5STR+Ecl1fV20Z6nFWhtbZza+3ykRyjqk6sqn9fRp/ZVXVXVW041Pa2qhrRuXvq95L8YZJJrbU9Ft/YBcfHq+qBqrq/qmZU1StXf5kA9JGwCsCwW5MctvBFVe2a5LfHrpxxa90k7x7rIlZUVa27grtsk2R2a+3Bp+jz/dbaRkk2TXJmkvOrarOVrRGA8UNYBWDYuUmOGHp9ZJJzhjtU1SZVdU5Vzauq26rqL6tqnW7bUVV1ZVWd3E39vLWqXtFtOynJPkk+0Y2kfWLosC+vqpur6ldV9cmqqiUVV1V7VNX3u35zq+oTVfW0oe0HVNVNVXVfVf1rVV2xcCS3qp5XVd+uqnuq6u6qOq+qNh3ad3ZVvbx7fmJVnd9d56+7KcJTh/q+v6ru6LbdVFX7V9VBSU5I8sbu+v6/p3if/zHJnw+ff+jYk7uR7AlDbZcPXcdRVfW9qjqlex9+VlUv6dpv70Ztj1zssJtX1aVdvVdU1TZDx35+t+3e7lreMLTt7Ko6raouqaoHk7xsCfU+u6ou7vafVVVHd+1vTfJvSfbu3o8PP8X7kdbagiRnJfmtJM+rqvW7n6OfV9WdVXV6Vf3W0HmP7s53b3f+Zw9ta1X1ru69ubuq/nHhz+gS6l/q9QMwtoRVAIZdleTpVbVjN4p2aJLFp7WemmSTJM9N8gcZhNu3DG3fM8lNSTZP8g9Jzqyqaq19KMl3kxzfWtuotXb80D6vTPLiJLsleUOSA5dS3+NJ3tsde+8k+yd5Z5LUYPryl5N8MMkzuxpeMrRvJfn7JM9OsmOSrZOc+BTvxauTfCGDEb+Lk3yiO88OSY5P8uLW2sZdrbNba/+V5O+SfLG7vhc8xbGnJ7k8yZ8/RZ+nsmeSmRlc5+e6Ol+c5HeTvCmDPwhsNNT/8CR/k8H7NiPJed21bJjk0u4Yz8rg+/2vVbXT0L5/nOSkJBsnWdK9nl9IMieD9/WPkvxdVe3XWjszybHpRk5ba9Oe6oK6cP62JA8kuTnJR5Jsn2RKd11bJfk/Xd/9MvheviHJlklu6+oY9tokU5PsnuSQJH+yhHMuz/UDMEaEVQAWt3B09Q+T3JjkjoUbhgLsB1trv26tzU7yT0nePLT/ba21T7fWHk/y2QzCxBbLOOdHWmu/aq39PMllGQSUJ2mtXdNau6q1Nr8796cyCMxJcnCS61trX2mtzU/y8SS/GNp3Vmvt0tbaI621eUn+eWjfJbmytXZJdx3nJlkYPh9Psn6Snapqvdba7NbaLcu4viX5P0n+tKomrsS+t7bWPtPV9sUMgvdfd9f2zSSPZhDwFvpaa+07rbVHknwog9HOrTP4I8Hs7ljzW2s/SnJBktcP7XtRa+17rbUFrbWHh4vojvHSJO9vrT3cWpuRwWjq8Oj8suxVVb/K4Ht1WAYh8/4kxyR5b2vt3tbarzP4Q8Ch3T6HJzmrtXZtd00f7K5p8tBxP9rt+/Mk/5Kh6e1Dluf6ARgjE5bdBYC1zLlJvpNk2yw2BTiDkbn1MhjJWui2DEa9FhoOiA91M3qHR/mW5BdDzx9aWv+q2j6DkDk1g3tpJyS5ptv87CS3D527VdWcoX23SPKxDKYib5zBH2x/uQI1bVBVE1prs6rqPRmMyu5cVd9I8mettf9dxjU+QWvtuqr6apIPZPBHgRVx59Dz33THW7xt+D0cfl8eqKp7M3i/tkmyZxcWF5qQwc/Ak/ZdgmcnWRgmF7otg+/P8rqqtfZ7ww1V9awMvr/XDM0Irwzu9V143msXbuiu6Z4Mfg5nL6Hu27p9Frc81w/AGDGyCsATtNZuy2ChpYOTfGWxzXcneSyDf+Qv9JwMjb4u6/AjLO+0JD9Jsl1r7ekZ3CO6MM3MTTJpYccapJxJQ/v+XXf+Xbt93zS07wpprX2uC1jbdMf86MJNK3ioaUmOzhPD/sLFiIYXtvqdlalzyNYLn3TTg5+R5H8zCHRXtNY2HXps1Fp7x9C+T3VN/5vkGVW18VDbivw8LM3dGQTunYfq2qRbiGnheYfvu90wgynRw+fdeuj5c7p9Frc81w/AGBFWAViStybZb/FVXLtpp+cnOamqNu4W6vmzPPm+1qW5M4N7XVfWxhlMEX2gqp6fZDhUfC3JrlX1mu7+x+PyxJC3cQb3Q95XVVsl+YuVKaCqdqiq/apq/SQPZxCqFnSb70wyeWmL+SyutTYrg2m87xpqm5dB6HpTVa1bVX+S5HkrU+uQg6vq92qwGNXfZDCaeXuSrybZvqreXFXrdY8XV9WOy1n/7Un+J8nfV9UGVbVbBj87y/vzsLTjLkjy6SSndKOsqaqtqmrhvcyfT/KWqprSfR/+LskPuqnhC/1FVW3WTVV+dwbv8+JGdP0ArFrCKgBP0lq7pbU2fSmb/zSD0b+fZbDgzucyWMV1eXwsyR/VYKXgj69EaX+ewYI/v84gzCwKIK21uzO41/AfktyTZKcMFjJ6pOvy4QwW27kvg2C7+Kjx8lo/g8V/7s5gqvCzMrhnMkm+1H29p6quXcK+S/LXSTZcrO3oDML0PUl2ziAQjsTnMhjFvTfJizIYVU43ffeADO4F/d8MruejGVzj8josyeRu/wuTTGut/fcI602S9yeZleSqqro/yX8n2aGr+7+T/FUG95fOzSDMH7rY/hdlMEV8Rgbf7zMXP8EoXT8Aq0i1NtIZWQDQP93o5pwkh7fWLhvrelh9qqplMFV81ljXAsDKM7IKwLhRVQdW1abd1NCF97NeNcZlAQArQVgFYDzZO8ktGUzRfVWS17TWfjO2JQEAK8M0YAAAAHrHyCoAAAC9M2GsC1iWzTffvE2ePHmsywAAAGCUXXPNNXe31iYuaVvvw+rkyZMzffrSPj0BAACANVVV3ba0baYBAwAA0DvCKgAAAL0jrAIAANA7vb9nFQAAYEU89thjmTNnTh5++OGxLoXOBhtskEmTJmW99dZb7n2EVQAAYFyZM2dONt5440yePDlVNdblrPVaa7nnnnsyZ86cbLvttsu9n2nAAADAuPLwww/nmc98pqDaE1WVZz7zmSs80i2sAgAA446g2i8r8/0QVgEAAOgdYRUAAIDeEVYBAIBxb/bs2dlll13GuozeuPzyy/M///M/i16ffvrpOeecc0bl2EcddVS+/OUvj/g4VgMGAABYQ7XW0lrLOuus2Djk5Zdfno022igveclLkiTHHnvsqihvRIysAgAAa4XHH388Rx99dHbeeecccMAB+c1vfpMZM2Zkr732ym677ZbXvva1+eUvf5kk2XffffPe9743U6dOzY477pirr746r3vd67LddtvlL//yLxcd89///d+zxx57ZMqUKXn729+exx9/fKnn/8xnPpPtt98+e+yxR44++ugcf/zxSZ48ErnRRhslSR544IHsv//+2X333bPrrrvmoosuSjIYJd5hhx1yxBFHZJdddsntt9+ed7zjHZk6dWp23nnnTJs2bdGxJk+enGnTpi06xk9+8pPMnj07p59+ek455ZRMmTIl3/3ud3PiiSfm5JNPXnTt73//+7PHHntk++23z3e/+91F799f/MVf5MUvfnF22223fOpTn0oyCMzHH398dthhh7z85S/PXXfdNeLvVSKsAgAAa4mbb745xx13XK6//vpsuummueCCC3LEEUfkox/9aGbOnJldd901H/7whxf1f9rTnpbp06fn2GOPzSGHHJJPfvKTue6663L22WfnnnvuyY033pgvfvGL+d73vpcZM2Zk3XXXzXnnnbfEc8+dOzfTpk3L9773vVx55ZW54YYbllnvBhtskAsvvDDXXnttLrvssrzvfe9La23Rtbzzne/M9ddfn2222SYnnXRSpk+fnpkzZ+aKK67IzJkzFx1n8803z7XXXpt3vOMdOfnkkzN58uQce+yxee9735sZM2Zkn332edK558+fnx/+8If5l3/5l0XvyZlnnplNNtkkV199da6++up8+tOfzq233poLL7wwN910U2644Yacc845T5hePBKmAQMAAGuFbbfdNlOmTEmSvOhFL8ott9ySX/3qV/mDP/iDJMmRRx6Z17/+9Yv6v/rVr06S7Lrrrtl5552z5ZZbJkme+9zn5vbbb8+VV16Za665Ji9+8YuTJL/5zW/yrGc9a4nn/sEPfpB99903EydOTJK88Y1vzE9/+tOnrLe1lhNOOCHf+c53ss466+SOO+7InXfemSTZZpttstdeey3qe/755+eMM87I/PnzM3fu3Nxwww3ZbbfdkiSve93rFl3zV77yleV6r4b3mT17dpLkm9/8ZmbOnLloFPi+++7LzTffnO985zs57LDDsu666+bZz3529ttvv+U6x7IIqwAAo6Ty4WV3WkO1TFt2J+i59ddff9HzddddN7/61a+Wq/8666zzhH3XWWedzJ8/P621HHnkkfn7v//7EdU1YcKELFiwIEmyYMGCPProo0mS8847L/Pmzcs111yT9dZbL5MnT87DDz+cJNlwww0X7X/rrbfm5JNPztVXX53NNtssRx111KJ+w9ex7rrrZv78+ctV05L2aa3l1FNPzYEHHviEvpdccsnKXPYymQYMAACslTbZZJNsttlmi+7JPPfccxeNsi6P/fffP1/+8pcX3aN577335rbbblti3z333DNXXHFF7rnnnjz22GP50pe+tGjb5MmTc8011yRJLr744jz22GNJBiOXz3rWs7LeeuvlsssuW+qx77///my44YbZZJNNcuedd+brX//6MmvfeOON8+tf/3q5rzVJDjzwwJx22mmL6vvpT3+aBx98ML//+7+fL37xi3n88cczd+7cXHbZZSt03KUxsgoAAKy1PvvZz+bYY4/NQw89lOc+97n5zGc+s9z77rTTTvnbv/3bHHDAAVmwYEHWW2+9fPKTn8w222zzpL5bbrllTjzxxOy9997ZdNNNF01HTpKjjz46hxxySF7wghfkoIMOWjRqevjhh+dVr3pVdt1110ydOjXPf/7zl1jHC17wgrzwhS/M85///Gy99dZ56UtfuszaX/WqV+WP/uiPctFFF+XUU09drut929veltmzZ2f33XdPay0TJ07Mf/zHf+S1r31tvv3tb2ennXbKc57znOy9997LdbxlqYU36PbV1KlT2/Tp08e6DACAZTINGPrhxhtvzI477jjWZTyls88+O9OnT88nPvGJsS5ltVnS96WqrmmtTV1Sf9OAAQAA6B3TgAEAAEbRnnvumUceeeQJbeeee2523XXXRa+POuqoHHXUUau5sjWLsAoAADCKfvCDH4x1CeOCacAAAAD0jrAKAABA7wirAAAA9I6wCgAAMEJVo/tYvnNW3ve+9y16ffLJJ+fEE09cNRc4BpYZVqtq66q6rKpuqKrrq+rdXfszqurSqrq5+7pZ115V9fGqmlVVM6tq96FjHdn1v7mqjlx1lwUAADC+rb/++vnKV76Su+++e6xLWSWWZ2R1fpL3tdZ2SrJXkuOqaqckH0jyrdbadkm+1b1Oklck2a57HJPktGQQbpNMS7Jnkj2STFsYcAEAAFgxEyZMyDHHHJNTTjnlSdtmz56d/fbbL7vttlv233///PznPx+DCkdmmWG1tTa3tXZt9/zXSW5MslWSQ5J8tuv22SSv6Z4fkuScNnBVkk2rasskBya5tLV2b2vtl0kuTXLQqF4NAADAWuS4447Leeedl/vuu+8J7X/6p3+aI488MjNnzszhhx+ed73rXWNU4cpboXtWq2pykhcm+UGSLVprc7tNv0iyRfd8qyS3D+02p2tbWvuSznNMVU2vqunz5s1bkRIBAADWGk9/+tNzxBFH5OMf//gT2r///e/nj//4j5Mkb37zm3PllVeORXkjstxhtao2SnJBkve01u4f3tZaa0naaBXVWjujtTa1tTZ14sSJo3VYAACAcec973lPzjzzzDz44INjXcqoWq6wWlXrZRBUz2utfaVrvrOb3pvu611d+x1Jth7afVLXtrR2AAAAVtIznvGMvOENb8iZZ565qO0lL3lJvvCFLyRJzjvvvOyzzz5jVd5KW57VgCvJmUlubK3989Cmi5MsXNH3yCQXDbUf0a0KvFeS+7rpwt9IckBVbdYtrHRA1wYAALBGa210Hyvqfe973xNWBT711FPzmc98JrvttlvOPffcfOxjHxvFq109JixHn5cmeXOSH1fVjK7thCQfSXJ+Vb01yW1J3tBtuyTJwUlmJXkoyVuSpLV2b1X9TZKru35/3Vq7d1SuAgAAYC3zwAMPLHq+xRZb5KGHHlr0eptttsm3v/3tsShr1CwzrLbWrkyytI+l3X8J/VuS45ZyrLOSnLUiBQIAALD2WaHVgAEAAGB1EFYBAADoHWEVAACA3hFWAQAA6B1hFQAAgN5Zno+uAQAA4ClUPjyqx2uZ9tTbW8s+++yTD33oQ3nFK16RJPnSl76UM888M//1X/81qrWMFWEVAABgDVNVOf300/P6178+L3vZyzJ//vyccMIJ4yaoJsIqAADAGmmXXXbJq171qnz0ox/Ngw8+mDe96U056aSTct111+Wxxx7LiSeemEMOOSTXX3993vKWt+TRRx/NggULcsEFF2S77bYb6/KXSVgFAABYQ02bNi277757nva0p+WVr3xl9ttvv5x11ln51a9+lT322CMvf/nLc/rpp+fd7353Dj/88Dz66KN5/PHHx7rs5SKsAgAArKE23HDDvPGNb8xGG22U888/P//5n/+Zk08+OUny8MMP5+c//3n23nvvnHTSSZkzZ05e97rXrRGjqomwCgAAsEZbZ511ss4666S1lgsuuCA77LDDE7bvuOOO2XPPPfO1r30tBx98cD71qU9lv/32G6Nql5+PrgEAABgHDjzwwJx66qlprSVJfvSjHyVJfvazn+W5z31u3vWud+WQQw7JzJkzx7LM5WZkFQAAYISW9VEzq8Nf/dVf5T3veU922223LFiwINtuu22++tWv5vzzz8+5556b9dZbL7/zO7+TE044YaxLXS61MHX31dSpU9v06dPHugwAgGUa7c9Z7JM+/EMclteNN96YHXfccazLYDFL+r5U1TWttalL6m8aMAAAAL0jrAIAANA7wioAADDu9P12x7XNynw/hFUAAGBc2WCDDXLPPfcIrD3RWss999yTDTbYYIX2sxowAAAwrkyaNClz5szJvHnzxroUOhtssEEmTZq0QvsIqwAAwLiy3nrrZdtttx3rMhgh04ABAADoHWEVAACA3hFWAQAA6B1hFQAAgN4RVgEAAOgdYRUAAIDeEVYBAADoHWEVAACA3llmWK2qs6rqrqq6bqjti1U1o3vMrqoZXfvkqvrN0LbTh/Z5UVX9uKpmVdXHq6pWzSUBAACwppuwHH3OTvKJJOcsbGitvXHh86r6pyT3DfW/pbU2ZQnHOS3J0Ul+kOSSJAcl+fqKlwwAAMB4t8yR1dbad5Lcu6Rt3ejoG5J8/qmOUVVbJnl6a+2q1lrLIPi+ZsXLBQAAYG0w0ntW90lyZ2vt5qG2bavqR1V1RVXt07VtlWTOUJ85XdsSVdUxVTW9qqbPmzdvhCUCAACwphlpWD0sTxxVnZvkOa21Fyb5sySfq6qnr+hBW2tntNamttamTpw4cYQlAgAAsKZZnntWl6iqJiR5XZIXLWxrrT2S5JHu+TVVdUuS7ZPckWTS0O6TujYAAAB4kpGMrL48yU9aa4um91bVxKpat3v+3CTbJflZa21ukvuraq/uPtcjklw0gnMDAAAwji3PR9d8Psn3k+xQVXOq6q3dpkPz5IWVfj/JzO6jbL6c5NjW2sLFmd6Z5N+SzEpyS6wEDAAAwFIscxpwa+2wpbQftYS2C5JcsJT+05PssoL1AQAAsBYa6QJLAAAAMOqEVQAAAHpHWAUAAKB3hFUAAAB6R1gFAACgd4RVAAAAekdYBQAAoHeEVQAAAHpHWAUAAKB3hFUAAAB6R1gFAACgd4RVAAAAekdYBQAAoHeEVQAAAHpHWAUAAKB3hFUAAAB6R1gFAACgd4RVAAAAekdYBQAAoHeEVQAAAHpHWAUAAKB3hFUAAAB6R1gFAACgd4RVAAAAekdYBQAAoHeEVQAAAHpHWAUAAKB3hFUAAAB6Z5lhtarOqqq7quq6obYTq+qOqprRPQ4e2vbBqppVVTdV1YFD7Qd1bbOq6gOjfykAAACMF8szsnp2koOW0H5Ka21K97gkSapqpySHJtm52+dfq2rdqlo3ySeTvCLJTkkO6/oCAADAk0xYVofW2neqavJyHu+QJF9orT2S5NaqmpVkj27brNbaz5Kkqr7Q9b1hhSsGAABg3BvJPavHV9XMbprwZl3bVkluH+ozp2tbWvsSVdUxVTW9qqbPmzdvBCUCAACwJlrZsHpakuclmZJkbpJ/GrWKkrTWzmitTW2tTZ04ceJoHhoAAIA1wDKnAS9Ja+3Ohc+r6tNJvtq9vCPJ1kNdJ3VteYp2AAAAeIKVGlmtqi2HXr42ycKVgi9OcmhVrV9V2ybZLskPk1ydZLuq2raqnpbBIkwXr3zZAAAAjGfLHFmtqs8n2TfJ5lU1J8m0JPtW1ZQkLcnsJG9Pktba9VV1fgYLJ81Pclxr7fHuOMcn+UaSdZOc1Vq7ftSvBgAAgHFheVYDPmwJzWc+Rf+Tkpy0hPZLklyyQtUBAACwVhrJasAAAACwSgirAAAA9I6wCgAAQO8IqwAAAPSOsAoAAEDvCKsAAAD0jrAKAABA7wirAAAA9I6wCgAAQO8IqwAAAPSOsAoAAEDvCKsAAAD0jrAKAABA7wirAAAA9I6wCgAAQO8IqwAAAPSOsAoAAEDvCKsAAAD0jrAKAABA7wirAAAA9I6wCgAAQO8IqwAAAPSOsAoAAEDvCKsAAAD0jrAKAABA7wirAAAA9I6wCgAAQO8IqwAAAPTOMsNqVZ1VVXdV1XVDbf9YVT+pqplVdWFVbdq1T66q31TVjO5x+tA+L6qqH1fVrKr6eFXVqrkkAAAA1nTLM7J6dpKDFmu7NMkurbXdkvw0yQeHtt3SWpvSPY4daj8tydFJtuseix8TAAAAkixHWG2tfSfJvYu1fbO1Nr97eVWSSU91jKraMsnTW2tXtdZaknOSvGblSgYAAGC8G417Vv8kydeHXm9bVT+qqiuqap+ubaskc4b6zOnalqiqjqmq6VU1fd68eaNQIgAAAGuSEYXVqvpQkvlJzuua5iZ5TmvthUn+LMnnqurpK3rc1toZrbWprbWpEydOHEmJAAAArIEmrOyOVXVUklcm2b+b2pvW2iNJHumeX1NVtyTZPskdeeJU4UldGwAAADzJSo2sVtVBSf7fJK9urT001D6xqtbtnj83g4WUftZam5vk/qraq1sF+IgkF424egAAAMalZY6sVtXnk+ybZPOqmpNkWgar/66f5NLuE2iu6lb+/f0kf11VjyVZkOTY1trCxZnemcHKwr+VwT2uw/e5AgAAwCLLDKuttcOW0HzmUvpekOSCpWybnmSXFaoOAACAtdJorAYMAAAAo0pYBQAAoHeEVQAAAHpHWAUAAKB3hFUAAAB6R1gFAACgd4RVAAAAekdYBQAAoHeEVQAAAHpHWAUAAKB3hFUAAAB6R1gFAACgd4RVAAAAekdYBQAAoHeEVQAAAHpHWAUAAKB3hFUAAAB6R1gFAACgd4RVAAAAekdYBQAAoHeEVQAAAHpHWAUAAKB3hFUAAAB6R1gFAACgd4RVAAAAekdYBQAAoHeEVQAAAHpHWAUAAKB3liusVtVZVXVXVV031PaMqrq0qm7uvm7WtVdVfbyqZlXVzKrafWifI7v+N1fVkaN/OQAAAIwHyzuyenaSgxZr+0CSb7XWtkvyre51krwiyXbd45gkpyWDcJtkWpI9k+yRZNrCgAsAAADDliustta+k+TexZoPSfLZ7vlnk7xmqP2cNnBVkk2rasskBya5tLV2b2vtl0kuzZMDMAAAAGTCCPbdorU2t3v+iyRbdM+3SnL7UL85XdvS2p+kqo7JYFQ2z3nOc0ZQIgDQJ1VjXcEq1sa6AIDxY1QWWGqttYzif55ba2e01qa21qZOnDhxtA4LAADAGmIkYfXObnpvuq93de13JNl6qN+krm1p7QAAAPAEIwmrFydZuKLvkUkuGmo/olsVeK8k93XThb+R5ICq2qxbWOmArg0AAACeYLnuWa2qzyfZN8nmVTUng1V9P5Lk/Kp6a5Lbkryh635JkoOTzEryUJK3JElr7d6q+pskV3f9/rq1tviiTQAAALB8YbW1dthSNu2/hL4tyXFLOc5ZSc5a7uoAAABYK43KAksAAAAwmoRVAAAAemckn7MKQA9VPjzWJaxSLdPGugQAYDUwsgoAAEDvCKsAAAD0jrAKAABA7wirAAAA9I6wCgAAQO8IqwAAAPSOsAoAAEDvCKsAAAD0jrAKAABA7wirAAAA9I6wCgAAQO9MGOsCAMZC1VhXsAq1sS4AAGDkjKwCAADQO8IqAAAAvSOsAgAA0DvCKgAAAL0jrAIAANA7wioAAAC9I6wCAADQO8IqAAAAvSOsAgAA0DvCKgAAAL0jrAIAANA7wioAAAC9I6wCAADQOysdVqtqh6qaMfS4v6reU1UnVtUdQ+0HD+3zwaqaVVU3VdWBo3yG2IoAAAu+SURBVHMJAAAAjDcTVnbH1tpNSaYkSVWtm+SOJBcmeUuSU1prJw/3r6qdkhyaZOckz07y31W1fWvt8ZWtAQAAgPFptKYB75/kltbabU/R55AkX2itPdJauzXJrCR7jNL5AQAAGEdGK6wemuTzQ6+Pr6qZVXVWVW3WtW2V5PahPnO6tiepqmOqanpVTZ83b94olQgAAMCaYsRhtaqeluTVSb7UNZ2W5HkZTBGem+SfVvSYrbUzWmtTW2tTJ06cONISAQAAWMOMxsjqK5Jc21q7M0laa3e21h5vrS1I8un836m+dyTZemi/SV0bAAAAPMFohNXDMjQFuKq2HNr22iTXdc8vTnJoVa1fVdsm2S7JD0fh/AAAAIwzK70acJJU1YZJ/jDJ24ea/6GqpiRpSWYv3NZau76qzk9yQ5L5SY6zEjAAAABLMqKw2lp7MMkzF2t781P0PynJSSM5JwAAAOPfaK0GDAAAAKNGWAUAAKB3hFUAAAB6R1gFAACgd4RVAAAAekdYBQAAoHeEVQAAAHpHWAUAAKB3hFUAAAB6R1gFAACgd4RVAAAAekdYBQAAoHeEVQAAAHpHWAUAAKB3hFUAAAB6R1gFAACgd4RVAAAAekdYBQAAoHeEVQAAAHpHWAUAAKB3hFUAAAB6R1gFAACgd4RVAAAAekdYBQAAoHeEVQAAAHpHWAUAAKB3hFUAAAB6R1gFAACgd0YcVqtqdlX9uKpmVNX0ru0ZVXVpVd3cfd2sa6+q+nhVzaqqmVW1+0jPDwAAwPgzWiOrL2utTWmtTe1efyDJt1pr2yX5Vvc6SV6RZLvucUyS00bp/AAAAIwjq2oa8CFJPts9/2yS1wy1n9MGrkqyaVVtuYpqAAAAYA01GmG1JflmVV1TVcd0bVu01uZ2z3+RZIvu+VZJbh/ad07X9gRVdUxVTa+q6fPmzRuFEgEAAFiTTBiFY/xea+2OqnpWkkur6ifDG1trraraihywtXZGkjOSZOrUqSu0LwAAAGu+EY+sttbu6L7eleTCJHskuXPh9N7u611d9zuSbD20+6SuDQAAABYZUVitqg2rauOFz5MckOS6JBcnObLrdmSSi7rnFyc5olsVeK8k9w1NFwYAAIAkI58GvEWSC6tq4bE+11r7r6q6Osn5VfXWJLcleUPX/5IkByeZleShJG8Z4fkBAAAYh0YUVltrP0vygiW035Nk/yW0tyTHjeScAAAAjH+r6qNrAAAAYKUJqwAAAPSOsAoAAEDvCKsAAAD0jrAKAABA7wirAAAA9I6wCgAAQO8IqwAAAPSOsAoAAEDvCKsAAAD0jrAKAABA7wirAAAA9I6wCgAAQO8IqwAAAPSOsAoAAEDvCKsAAAD0zoSxLgAAAGAkKh8e6xJWqZZpY13CmDCyCgAAQO8IqwAAAPSOsAoAAEDvCKsAAAD0jrAKAABA7wirAAAA9I6wCgAAQO8IqwAAAPSOsAoAAEDvCKsAAAD0jrAKAABA76x0WK2qravqsqq6oaqur6p3d+0nVtUdVTWjexw8tM8Hq2pWVd1UVQeOxgUAAAAw/kwYwb7zk7yvtXZtVW2c5JqqurTbdkpr7eThzlW1U5JDk+yc5NlJ/ruqtm+tPT6CGgAAABiHVnpktbU2t7V2bff810luTLLVU+xySJIvtNYeaa3dmmRWkj1W9vwAAACMX6Nyz2pVTU7ywiQ/6JqOr6qZVXVWVW3WtW2V5Pah3eZkKeG2qo6pqulVNX3evHmjUSIAAABrkBGH1araKMkFSd7TWrs/yWlJnpdkSpK5Sf5pRY/ZWjujtTa1tTZ14sSJIy0RAACANcyIwmpVrZdBUD2vtfaVJGmt3dlae7y1tiDJp/N/p/rekWTrod0ndW0AAADwBCNZDbiSnJnkxtbaPw+1bznU7bVJruueX5zk0Kpav6q2TbJdkh+u7PkBAAAYv0ayGvBLk7w5yY+rakbXdkKSw6pqSpKWZHaStydJa+36qjo/yQ0ZrCR8nJWAAQAAWJKVDquttSuT1BI2XfIU+5yU5KSVPScAAABrh1FZDRgAAABGk7AKAABA7wirAAAA9I6wCgAAQO8IqwAAAPSOsAoAAEDvCKsAAAD0jrAKAABA7wirAAAA9I6wCgAAQO8IqwAAAPSOsAoAAEDvCKsAAAD0jrAKAABA7wirAAAA9I6wCgAAQO8IqwAAAPSOsAoAAEDvCKsAAAD0jrAKAABA7wirAAAA9I6wCgAAQO8IqwAAAPSOsAoAAEDvCKsAAAD0zoSxLgAAAFi1qsa6glWsjXUBrApGVgEAAOgdYRUAAIDeWe1htaoOqqqbqmpWVX1gdZ8fAACA/lutYbWq1k3yySSvSLJTksOqaqfVWQMAAAD9t7pHVvdIMqu19rPW2qNJvpDkkNVcAwAAAD23ulcD3irJ7UOv5yTZc/FOVXVMkmO6lw9U1U2roTZG3+ZJ7h7rImCtU+P7d69y4liXAEs3jn///O7Ra+P4dy8Z979/2yxtQy8/uqa1dkaSM8a6Dkamqqa31qaOdR2wtvG7B2PH7x+MDb9749PqngZ8R5Kth15P6toAAABgkdUdVq9Osl1VbVtVT0tyaJKLV3MNAAAA9NxqnQbcWptfVccn+UaSdZOc1Vq7fnXWwGplKjeMDb97MHb8/sHY8Ls3DlVrbaxrAAAAgCdY3dOAAQAAYJmEVQAAAHpHWAUAAKB3hFUAAAB6R1hl1FTV86tq/6raaLH2g8aqJlgbVNUeVfXi7vlOVfVnVXXwWNcFa5uqOmesa4C1UVX9Xvf/vgPGuhZGl9WAGRVV9a4kxyW5McmUJO9urV3Ubbu2tbb7WNYH41VVTUvyigw+iuzSJHsmuSzJHyb5RmvtpDEsD8atqlr8c+IrycuSfDtJWmuvXu1FwVqiqn7YWtuje350Bv8GvTDJAUn+s7X2kbGsj9EjrDIqqurHSfZurT1QVZOTfDnJua21j1XVj1prLxzTAmGc6n73piRZP8kvkkxqrd1fVb+V5Aettd3GtEAYp6rq2iQ3JPm3JC2DsPr5JIcmSWvtirGrDsa34X9bVtXVSQ5urc2rqg2TXNVa23VsK2S0mAbMaFmntfZAkrTWZifZN8krquqfM/gfOLBqzG+tPd5aeyjJLa21+5OktfabJAvGtjQY16YmuSbJh5Lc11q7PMlvWmtXCKqwyq1TVZtV1TMzGHyblySttQeTzB/b0hhNE8a6AMaNO6tqSmttRpJ0I6yvTHJWEn/dglXn0ar67S6svmhhY1VtEmEVVpnW2oIkp1TVl7qvd8a/q2B12SSDPxZVklZVW7bW5nbrphgkGUdMA2ZUVNWkDEZ4frGEbS9trX1vDMqCca+q1m+tPbKE9s2TbNla+/EYlAVrnar6f5K8tLV2wljXAmurqvrtJFu01m4d61oYHcIqAAAAveOeVQAAAHpHWAUAAKB3hFUAWANU1aZV9c6h1/tW1VfHsiYAWJWEVQBYM2ya5J3L7AUA44SwCgCjrKomV9VPqursqvppVZ1XVS+vqu9V1c1VtUdVPaOq/qOqZlbVVVW1W7fviVV1VlVdXlU/q6p3dYf9SJLnVdWMqvrHrm2jqvpyd67zqspHNgAwbvg8MABYNX43yeuT/EmSq5P8cZLfS/LqJCckuT3Jj1prr6mq/ZKck2RKt+/zk7wsycZJbqqq05J8IMkurbUpyWAacJIXJtk5yf8m+V6Slya5cnVcHACsakZWAWDVuLW19uPW2oIk1yf5Vht8XtyPk0zOILiemySttW8neWZVPb3b92uttUdaa3cnuSvJFks5xw9ba3O6c8zojgsA44KwCgCrxiNDzxcMvV6QZc9sGt738afov7z9AGCNI6wCwNj4bpLDk0VTeu9urd3/FP1/ncG0YABYK/gLLACMjROTnFVVM5M8lOTIp+rcWrunW6DpuiRfT/K1VV8iAIydGtw+AwAAAP1hGjAAAAC9I6wCAADQO8IqAAAAvSOsAgAA0DvCKgAAAL0jrAIAANA7wioAAAC98/8DM+GnRkufzD0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data1_test1.plot(kind='bar', title=\"Month against Number of People\", figsize=[16,6], colormap='winter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KvQ1BHNfX9E"
   },
   "source": [
    "## Which age group is the most affected with Covid-19?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "nivPNSAxgSz9",
    "outputId": "f4ed1520-5795-4ba3-f66f-a0288e8182d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count        12070\n",
       "unique          17\n",
       "top       30 to 34\n",
       "freq          1510\n",
       "Name: age_group, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['age_group'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "t0LXzCOyhkCh",
    "outputId": "c34030dd-63d8-4a9e-cba7-6593ce30a3ad"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>age_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38.0</td>\n",
       "      <td>35 to 39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.0</td>\n",
       "      <td>40 to 44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60.0</td>\n",
       "      <td>60 to 64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>45 to 49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62.0</td>\n",
       "      <td>60 to 64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12086</th>\n",
       "      <td>35.0</td>\n",
       "      <td>35 to 39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12087</th>\n",
       "      <td>37.0</td>\n",
       "      <td>35 to 39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12088</th>\n",
       "      <td>62.0</td>\n",
       "      <td>60 to 64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12089</th>\n",
       "      <td>18.0</td>\n",
       "      <td>15 to 19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12090</th>\n",
       "      <td>50.0</td>\n",
       "      <td>50 to 54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12091 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age age_group\n",
       "0      38.0  35 to 39\n",
       "1      44.0  40 to 44\n",
       "2      60.0  60 to 64\n",
       "3      48.0  45 to 49\n",
       "4      62.0  60 to 64\n",
       "...     ...       ...\n",
       "12086  35.0  35 to 39\n",
       "12087  37.0  35 to 39\n",
       "12088  62.0  60 to 64\n",
       "12089  18.0  15 to 19\n",
       "12090  50.0  50 to 54\n",
       "\n",
       "[12091 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = df[['age','age_group']]\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "id": "2KltFfTRh2qB",
    "outputId": "bbdc11f4-a612-4fbe-bc07-3c13654afd29"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_group  age  \n",
       "0 to 4     0.0      57\n",
       "           1.0      31\n",
       "           2.0      24\n",
       "           3.0      21\n",
       "           4.0      21\n",
       "                    ..\n",
       "80+        96.0      3\n",
       "           99.0      3\n",
       "           95.0      2\n",
       "           97.0      1\n",
       "           101.0     1\n",
       "Name: age, Length: 100, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2_count = data2.groupby([\"age_group\"])[\"age\"].value_counts()\n",
    "data2_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XEqA_18zalR4"
   },
   "source": [
    "Group by age group to find the total case for each age group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "id": "G8r3n9IalymA",
    "outputId": "e5a52a36-9598-49f2-d3da-93a472e5384a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_group\n",
       "0 to 4       154\n",
       "10 to 14     169\n",
       "15 to 19     282\n",
       "20 to 24     767\n",
       "25 to 29    1289\n",
       "30 to 34    1510\n",
       "35 to 39    1061\n",
       "40 to 44     967\n",
       "45 to 49    1002\n",
       "5 to 9       122\n",
       "50 to 54     973\n",
       "55 to 59     967\n",
       "60 to 64     921\n",
       "65 to 69     713\n",
       "70 to 74     565\n",
       "75 to 79     287\n",
       "80+          321\n",
       "Name: age, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.groupby([\"age_group\"])[\"age\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lbBStkpsatkp"
   },
   "source": [
    "Add the total case for each group into a new column named 'count'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 539
    },
    "id": "Gm_zwWttkJas",
    "outputId": "ab9aa013-4307-4305-ac2c-fbdd15c10ccb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>age_group</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38.0</td>\n",
       "      <td>35 to 39</td>\n",
       "      <td>1061.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.0</td>\n",
       "      <td>40 to 44</td>\n",
       "      <td>967.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60.0</td>\n",
       "      <td>60 to 64</td>\n",
       "      <td>921.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>45 to 49</td>\n",
       "      <td>1002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62.0</td>\n",
       "      <td>60 to 64</td>\n",
       "      <td>921.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12086</th>\n",
       "      <td>35.0</td>\n",
       "      <td>35 to 39</td>\n",
       "      <td>1061.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12087</th>\n",
       "      <td>37.0</td>\n",
       "      <td>35 to 39</td>\n",
       "      <td>1061.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12088</th>\n",
       "      <td>62.0</td>\n",
       "      <td>60 to 64</td>\n",
       "      <td>921.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12089</th>\n",
       "      <td>18.0</td>\n",
       "      <td>15 to 19</td>\n",
       "      <td>282.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12090</th>\n",
       "      <td>50.0</td>\n",
       "      <td>50 to 54</td>\n",
       "      <td>973.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12091 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age age_group   count\n",
       "0      38.0  35 to 39  1061.0\n",
       "1      44.0  40 to 44   967.0\n",
       "2      60.0  60 to 64   921.0\n",
       "3      48.0  45 to 49  1002.0\n",
       "4      62.0  60 to 64   921.0\n",
       "...     ...       ...     ...\n",
       "12086  35.0  35 to 39  1061.0\n",
       "12087  37.0  35 to 39  1061.0\n",
       "12088  62.0  60 to 64   921.0\n",
       "12089  18.0  15 to 19   282.0\n",
       "12090  50.0  50 to 54   973.0\n",
       "\n",
       "[12091 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2['count'] = data2.groupby([\"age_group\"])[\"age\"].transform('count')\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EweLHKJ2a0yt"
   },
   "outputs": [],
   "source": [
    "Drop Nan value in the new data frame that include count column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "vPViyhMrnWqU",
    "outputId": "d1fddf2e-365d-4018-c43a-209289952b83"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>age_group</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38.0</td>\n",
       "      <td>35 to 39</td>\n",
       "      <td>1061.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.0</td>\n",
       "      <td>40 to 44</td>\n",
       "      <td>967.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60.0</td>\n",
       "      <td>60 to 64</td>\n",
       "      <td>921.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>45 to 49</td>\n",
       "      <td>1002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62.0</td>\n",
       "      <td>60 to 64</td>\n",
       "      <td>921.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12065</th>\n",
       "      <td>35.0</td>\n",
       "      <td>35 to 39</td>\n",
       "      <td>1061.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12066</th>\n",
       "      <td>37.0</td>\n",
       "      <td>35 to 39</td>\n",
       "      <td>1061.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12067</th>\n",
       "      <td>62.0</td>\n",
       "      <td>60 to 64</td>\n",
       "      <td>921.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12068</th>\n",
       "      <td>18.0</td>\n",
       "      <td>15 to 19</td>\n",
       "      <td>282.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12069</th>\n",
       "      <td>50.0</td>\n",
       "      <td>50 to 54</td>\n",
       "      <td>973.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12070 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age age_group   count\n",
       "0      38.0  35 to 39  1061.0\n",
       "1      44.0  40 to 44   967.0\n",
       "2      60.0  60 to 64   921.0\n",
       "3      48.0  45 to 49  1002.0\n",
       "4      62.0  60 to 64   921.0\n",
       "...     ...       ...     ...\n",
       "12065  35.0  35 to 39  1061.0\n",
       "12066  37.0  35 to 39  1061.0\n",
       "12067  62.0  60 to 64   921.0\n",
       "12068  18.0  15 to 19   282.0\n",
       "12069  50.0  50 to 54   973.0\n",
       "\n",
       "[12070 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2= data2.dropna()\n",
    "data2= data2.reset_index(drop=True)\n",
    "data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2y2bjtEKa8Jq"
   },
   "source": [
    "Sort the data according to age_group column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SguUkZqmmKUS"
   },
   "outputs": [],
   "source": [
    "data2.sort_values(\"age_group\", inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijFnRO13bDqn"
   },
   "source": [
    "Drop duplicates data in age_group column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 570
    },
    "id": "IXnc54kFn0fj",
    "outputId": "77e6f246-3b1d-49bb-edd9-30af5acb6a4f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>age_group</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4016</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0 to 4</td>\n",
       "      <td>154.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10040</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10 to 14</td>\n",
       "      <td>169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9927</th>\n",
       "      <td>18.0</td>\n",
       "      <td>15 to 19</td>\n",
       "      <td>282.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10340</th>\n",
       "      <td>24.0</td>\n",
       "      <td>20 to 24</td>\n",
       "      <td>767.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3631</th>\n",
       "      <td>28.0</td>\n",
       "      <td>25 to 29</td>\n",
       "      <td>1289.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4630</th>\n",
       "      <td>30.0</td>\n",
       "      <td>30 to 34</td>\n",
       "      <td>1510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10940</th>\n",
       "      <td>35.0</td>\n",
       "      <td>35 to 39</td>\n",
       "      <td>1061.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9555</th>\n",
       "      <td>42.0</td>\n",
       "      <td>40 to 44</td>\n",
       "      <td>967.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6820</th>\n",
       "      <td>45.0</td>\n",
       "      <td>45 to 49</td>\n",
       "      <td>1002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11309</th>\n",
       "      <td>8.0</td>\n",
       "      <td>5 to 9</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10074</th>\n",
       "      <td>51.0</td>\n",
       "      <td>50 to 54</td>\n",
       "      <td>973.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3047</th>\n",
       "      <td>57.0</td>\n",
       "      <td>55 to 59</td>\n",
       "      <td>967.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>62.0</td>\n",
       "      <td>60 to 64</td>\n",
       "      <td>921.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599</th>\n",
       "      <td>65.0</td>\n",
       "      <td>65 to 69</td>\n",
       "      <td>713.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2775</th>\n",
       "      <td>74.0</td>\n",
       "      <td>70 to 74</td>\n",
       "      <td>565.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>79.0</td>\n",
       "      <td>75 to 79</td>\n",
       "      <td>287.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11054</th>\n",
       "      <td>87.0</td>\n",
       "      <td>80+</td>\n",
       "      <td>321.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age age_group   count\n",
       "4016    2.0    0 to 4   154.0\n",
       "10040  10.0  10 to 14   169.0\n",
       "9927   18.0  15 to 19   282.0\n",
       "10340  24.0  20 to 24   767.0\n",
       "3631   28.0  25 to 29  1289.0\n",
       "4630   30.0  30 to 34  1510.0\n",
       "10940  35.0  35 to 39  1061.0\n",
       "9555   42.0  40 to 44   967.0\n",
       "6820   45.0  45 to 49  1002.0\n",
       "11309   8.0    5 to 9   122.0\n",
       "10074  51.0  50 to 54   973.0\n",
       "3047   57.0  55 to 59   967.0\n",
       "1352   62.0  60 to 64   921.0\n",
       "2599   65.0  65 to 69   713.0\n",
       "2775   74.0  70 to 74   565.0\n",
       "50     79.0  75 to 79   287.0\n",
       "11054  87.0       80+   321.0"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.drop_duplicates(subset=\"age_group\", inplace=True)\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_P6jHoAXub3b"
   },
   "outputs": [],
   "source": [
    "data2 = data2.groupby('age_group')['count'].sum().to_frame().reset_index().sort_values(by='age_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 570
    },
    "id": "p8kVyJ-_VjHN",
    "outputId": "e66eab3e-ae92-4e66-e08a-22c54cd17e7b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_group</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0 to 4</td>\n",
       "      <td>154.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10 to 14</td>\n",
       "      <td>169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15 to 19</td>\n",
       "      <td>282.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20 to 24</td>\n",
       "      <td>767.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25 to 29</td>\n",
       "      <td>1289.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30 to 34</td>\n",
       "      <td>1510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>35 to 39</td>\n",
       "      <td>1061.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>40 to 44</td>\n",
       "      <td>967.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>45 to 49</td>\n",
       "      <td>1002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5 to 9</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50 to 54</td>\n",
       "      <td>973.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>55 to 59</td>\n",
       "      <td>967.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>60 to 64</td>\n",
       "      <td>921.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>65 to 69</td>\n",
       "      <td>713.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>70 to 74</td>\n",
       "      <td>565.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>75 to 79</td>\n",
       "      <td>287.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>80+</td>\n",
       "      <td>321.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age_group   count\n",
       "0     0 to 4   154.0\n",
       "1   10 to 14   169.0\n",
       "2   15 to 19   282.0\n",
       "3   20 to 24   767.0\n",
       "4   25 to 29  1289.0\n",
       "5   30 to 34  1510.0\n",
       "6   35 to 39  1061.0\n",
       "7   40 to 44   967.0\n",
       "8   45 to 49  1002.0\n",
       "9     5 to 9   122.0\n",
       "10  50 to 54   973.0\n",
       "11  55 to 59   967.0\n",
       "12  60 to 64   921.0\n",
       "13  65 to 69   713.0\n",
       "14  70 to 74   565.0\n",
       "15  75 to 79   287.0\n",
       "16       80+   321.0"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "0DZAxk0fijnV",
    "outputId": "786116ed-ae26-41b7-8706-b2b6d1121a2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_group    category\n",
       "count         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W9-LEyJ-emB1"
   },
   "outputs": [],
   "source": [
    "data2['count'] = pd.to_numeric(data2['count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9D1s1hNfbRR7"
   },
   "source": [
    "Plot the bar graph accodrding to the age_group and total number of Covid-19 case for each age group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "id": "ZW5uiQwLbiD-",
    "outputId": "d540eefd-1400-4ea7-f3ee-40997f5a6013"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data2.plot(x ='age_group', y='count', kind = 'bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bLR8r_KmjUTC"
   },
   "source": [
    "##Which age group has the highest risk of death when affected with covid19?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "zuMzHorjjWKJ",
    "outputId": "e129ca9a-92a6-4b6d-ae5e-8bc465c1970d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count              12091\n",
       "unique                 5\n",
       "top       For validation\n",
       "freq                5790\n",
       "Name: status, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['status'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FudFsm7tbgA_"
   },
   "source": [
    "Select age_group, age and status column to do the analysis and put the selected column in a new data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "ptM-6GSpjoFZ",
    "outputId": "17c21360-6963-4a6c-d51c-55ca6a36345d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_group</th>\n",
       "      <th>age</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35 to 39</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Recovered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40 to 44</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Died</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60 to 64</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Recovered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45 to 49</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Recovered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60 to 64</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Died</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12086</th>\n",
       "      <td>35 to 39</td>\n",
       "      <td>35.0</td>\n",
       "      <td>For validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12087</th>\n",
       "      <td>35 to 39</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Died</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12088</th>\n",
       "      <td>60 to 64</td>\n",
       "      <td>62.0</td>\n",
       "      <td>For validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12089</th>\n",
       "      <td>15 to 19</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Home quarantined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12090</th>\n",
       "      <td>50 to 54</td>\n",
       "      <td>50.0</td>\n",
       "      <td>For validation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12091 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age_group   age            status\n",
       "0      35 to 39  38.0         Recovered\n",
       "1      40 to 44  44.0              Died\n",
       "2      60 to 64  60.0         Recovered\n",
       "3      45 to 49  48.0         Recovered\n",
       "4      60 to 64  62.0              Died\n",
       "...         ...   ...               ...\n",
       "12086  35 to 39  35.0    For validation\n",
       "12087  35 to 39  37.0              Died\n",
       "12088  60 to 64  62.0    For validation\n",
       "12089  15 to 19  18.0  Home quarantined\n",
       "12090  50 to 54  50.0    For validation\n",
       "\n",
       "[12091 rows x 3 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3 = df[['age_group','age','status']]\n",
    "data3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9W0akyXbxfQ"
   },
   "source": [
    "Drop rows in the new data frame that have the Nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "nywmSFfcOgus",
    "outputId": "d595303f-7e73-4fad-8909-799084394ecf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_group</th>\n",
       "      <th>age</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35 to 39</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Recovered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40 to 44</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Died</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60 to 64</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Recovered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45 to 49</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Recovered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60 to 64</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Died</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12065</th>\n",
       "      <td>35 to 39</td>\n",
       "      <td>35.0</td>\n",
       "      <td>For validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12066</th>\n",
       "      <td>35 to 39</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Died</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12067</th>\n",
       "      <td>60 to 64</td>\n",
       "      <td>62.0</td>\n",
       "      <td>For validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12068</th>\n",
       "      <td>15 to 19</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Home quarantined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12069</th>\n",
       "      <td>50 to 54</td>\n",
       "      <td>50.0</td>\n",
       "      <td>For validation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12070 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age_group   age            status\n",
       "0      35 to 39  38.0         Recovered\n",
       "1      40 to 44  44.0              Died\n",
       "2      60 to 64  60.0         Recovered\n",
       "3      45 to 49  48.0         Recovered\n",
       "4      60 to 64  62.0              Died\n",
       "...         ...   ...               ...\n",
       "12065  35 to 39  35.0    For validation\n",
       "12066  35 to 39  37.0              Died\n",
       "12067  60 to 64  62.0    For validation\n",
       "12068  15 to 19  18.0  Home quarantined\n",
       "12069  50 to 54  50.0    For validation\n",
       "\n",
       "[12070 rows x 3 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3= data3.dropna()\n",
    "data3= data3.reset_index(drop=True)\n",
    "data3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GACU3FuicAWC"
   },
   "source": [
    "Group the data according to the age group and the patient status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "id": "OG4kGN4Mj7Rt",
    "outputId": "13e7cdc9-6f76-4410-80ee-d6deadebf41c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_group  status          \n",
       "0 to 4     For validation      100\n",
       "           Admitted             22\n",
       "           Recovered            14\n",
       "           Home quarantined     11\n",
       "           Died                  7\n",
       "                              ... \n",
       "80+        Died                108\n",
       "           For validation       90\n",
       "           Admitted             72\n",
       "           Recovered            37\n",
       "           Home quarantined     14\n",
       "Name: status, Length: 85, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3_count = data3.groupby([\"age_group\"])[\"status\"].value_counts()\n",
    "data3_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "id": "OT9hvXXBkUau",
    "outputId": "67f8be91-58fc-4a7a-bb4c-b9a02291e33f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_group\n",
       "0 to 4       154\n",
       "10 to 14     169\n",
       "15 to 19     282\n",
       "20 to 24     767\n",
       "25 to 29    1289\n",
       "30 to 34    1510\n",
       "35 to 39    1061\n",
       "40 to 44     967\n",
       "45 to 49    1002\n",
       "5 to 9       122\n",
       "50 to 54     973\n",
       "55 to 59     967\n",
       "60 to 64     921\n",
       "65 to 69     713\n",
       "70 to 74     565\n",
       "75 to 79     287\n",
       "80+          321\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    " data3_count1= data3.groupby(\"age_group\")[\"status\"].count()\n",
    " data3_count1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ov07gq2BcHQt"
   },
   "source": [
    "Use unstack function to separate the unique data from status column into 5 differents new column. The data in the new columns is a value accumulate from each of the age_group column. Then, add 3 more additional columns which are total, Died_percent, and Recovered_percent. The formula has been added into the code for calculating the Died percentange and Recovered percentage for each age group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 601
    },
    "id": "clFBMGKarUy6",
    "outputId": "caa62c74-036d-4118-cdcb-e3e91924de80"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>status</th>\n",
       "      <th>Admitted</th>\n",
       "      <th>Died</th>\n",
       "      <th>for_validation</th>\n",
       "      <th>home_quarantined</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>total</th>\n",
       "      <th>Died_percent</th>\n",
       "      <th>Recovered_percent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0 to 4</th>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>154</td>\n",
       "      <td>4.55</td>\n",
       "      <td>9.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10 to 14</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>169</td>\n",
       "      <td>0.59</td>\n",
       "      <td>4.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15 to 19</th>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>228</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>282</td>\n",
       "      <td>1.42</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20 to 24</th>\n",
       "      <td>97</td>\n",
       "      <td>3</td>\n",
       "      <td>451</td>\n",
       "      <td>90</td>\n",
       "      <td>126</td>\n",
       "      <td>767</td>\n",
       "      <td>0.39</td>\n",
       "      <td>16.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25 to 29</th>\n",
       "      <td>140</td>\n",
       "      <td>6</td>\n",
       "      <td>718</td>\n",
       "      <td>184</td>\n",
       "      <td>241</td>\n",
       "      <td>1289</td>\n",
       "      <td>0.47</td>\n",
       "      <td>18.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30 to 34</th>\n",
       "      <td>185</td>\n",
       "      <td>11</td>\n",
       "      <td>745</td>\n",
       "      <td>230</td>\n",
       "      <td>339</td>\n",
       "      <td>1510</td>\n",
       "      <td>0.73</td>\n",
       "      <td>22.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35 to 39</th>\n",
       "      <td>129</td>\n",
       "      <td>20</td>\n",
       "      <td>563</td>\n",
       "      <td>130</td>\n",
       "      <td>219</td>\n",
       "      <td>1061</td>\n",
       "      <td>1.89</td>\n",
       "      <td>20.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40 to 44</th>\n",
       "      <td>128</td>\n",
       "      <td>30</td>\n",
       "      <td>506</td>\n",
       "      <td>114</td>\n",
       "      <td>189</td>\n",
       "      <td>967</td>\n",
       "      <td>3.10</td>\n",
       "      <td>19.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45 to 49</th>\n",
       "      <td>151</td>\n",
       "      <td>38</td>\n",
       "      <td>483</td>\n",
       "      <td>103</td>\n",
       "      <td>227</td>\n",
       "      <td>1002</td>\n",
       "      <td>3.79</td>\n",
       "      <td>22.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 to 9</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>122</td>\n",
       "      <td>0.82</td>\n",
       "      <td>9.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50 to 54</th>\n",
       "      <td>137</td>\n",
       "      <td>60</td>\n",
       "      <td>441</td>\n",
       "      <td>101</td>\n",
       "      <td>234</td>\n",
       "      <td>973</td>\n",
       "      <td>6.17</td>\n",
       "      <td>24.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55 to 59</th>\n",
       "      <td>172</td>\n",
       "      <td>77</td>\n",
       "      <td>416</td>\n",
       "      <td>82</td>\n",
       "      <td>220</td>\n",
       "      <td>967</td>\n",
       "      <td>7.96</td>\n",
       "      <td>22.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60 to 64</th>\n",
       "      <td>168</td>\n",
       "      <td>129</td>\n",
       "      <td>348</td>\n",
       "      <td>68</td>\n",
       "      <td>208</td>\n",
       "      <td>921</td>\n",
       "      <td>14.01</td>\n",
       "      <td>22.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65 to 69</th>\n",
       "      <td>153</td>\n",
       "      <td>125</td>\n",
       "      <td>193</td>\n",
       "      <td>50</td>\n",
       "      <td>192</td>\n",
       "      <td>713</td>\n",
       "      <td>17.53</td>\n",
       "      <td>26.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70 to 74</th>\n",
       "      <td>123</td>\n",
       "      <td>109</td>\n",
       "      <td>163</td>\n",
       "      <td>44</td>\n",
       "      <td>126</td>\n",
       "      <td>565</td>\n",
       "      <td>19.29</td>\n",
       "      <td>22.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75 to 79</th>\n",
       "      <td>55</td>\n",
       "      <td>77</td>\n",
       "      <td>88</td>\n",
       "      <td>9</td>\n",
       "      <td>58</td>\n",
       "      <td>287</td>\n",
       "      <td>26.83</td>\n",
       "      <td>20.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80+</th>\n",
       "      <td>72</td>\n",
       "      <td>108</td>\n",
       "      <td>90</td>\n",
       "      <td>14</td>\n",
       "      <td>37</td>\n",
       "      <td>321</td>\n",
       "      <td>33.64</td>\n",
       "      <td>11.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "status     Admitted  Died  ...  Died_percent  Recovered_percent\n",
       "age_group                  ...                                 \n",
       "0 to 4           22     7  ...          4.55               9.09\n",
       "10 to 14          8     1  ...          0.59               4.14\n",
       "15 to 19         25     4  ...          1.42               3.55\n",
       "20 to 24         97     3  ...          0.39              16.43\n",
       "25 to 29        140     6  ...          0.47              18.70\n",
       "30 to 34        185    11  ...          0.73              22.45\n",
       "35 to 39        129    20  ...          1.89              20.64\n",
       "40 to 44        128    30  ...          3.10              19.54\n",
       "45 to 49        151    38  ...          3.79              22.65\n",
       "5 to 9            5     1  ...          0.82               9.84\n",
       "50 to 54        137    60  ...          6.17              24.05\n",
       "55 to 59        172    77  ...          7.96              22.75\n",
       "60 to 64        168   129  ...         14.01              22.58\n",
       "65 to 69        153   125  ...         17.53              26.93\n",
       "70 to 74        123   109  ...         19.29              22.30\n",
       "75 to 79         55    77  ...         26.83              20.21\n",
       "80+              72   108  ...         33.64              11.53\n",
       "\n",
       "[17 rows x 8 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3_status = data3.groupby('age_group')['status'].value_counts().unstack().fillna(0)\n",
    "data3_status.rename(columns = {'Home quarantined':'home_quarantined'}, inplace = True)\n",
    "data3_status.rename(columns = {'For validation':'for_validation'}, inplace = True)\n",
    "data3_status['total'] = data3_status.apply(lambda row: row.Admitted + row.Died + row.for_validation + row.home_quarantined + row.Recovered, axis=1)\n",
    "data3_status['Died_percent'] = data3_status.apply(lambda row: row.Died/ row.total * 100, axis=1)\n",
    "data3_status['Recovered_percent'] = data3_status.apply(lambda row: row.Recovered/ row.total * 100, axis=1)\n",
    "data3_status = data3_status.round(2)\n",
    "data3_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "id": "zAIsLGDbzMwi",
    "outputId": "816ff8ad-a06e-41ef-9c45-795baca14903"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status\n",
       "Admitted               int64\n",
       "Died                   int64\n",
       "for_validation         int64\n",
       "home_quarantined       int64\n",
       "Recovered              int64\n",
       "total                  int64\n",
       "Died_percent         float64\n",
       "Recovered_percent    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3_status.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQTacb1xdCAK"
   },
   "source": [
    "To find the maximum number of Die based on age group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "TVtOgxDc_TFE",
    "outputId": "9eb2dbfb-2608-42e9-a72c-b1f2d9582f97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129\n"
     ]
    }
   ],
   "source": [
    "data3_status = data3_status[\"Died\"]\n",
    "maxDie = data3_status.max()\n",
    "print(maxDie)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xq5R2ypWdKaR"
   },
   "source": [
    "Plotting a graph for Died percentage based on age group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "id": "GsuvrgJCuoYl",
    "outputId": "47479441-6c46-4bd0-cf47-f277d74df6d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb63fdc7d30>"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data3_status.plot.bar(y='Died_percent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LjcsBgz0_bVH"
   },
   "source": [
    "#Which province in the Philippine has led to the increased number of cases in the Philippine?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4v62xXu6dge9"
   },
   "source": [
    "Select case_id and province column to do the analysis and put it into a new data frame. \n",
    "Drop rows that contain Nan values inside the data frame.\n",
    "Count the number of cases according to the province\n",
    "Drop column case_id.\n",
    "Drop duplicates values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "0jwLkJ3-wbvq",
    "outputId": "7fd400e1-c0a0-4c6c-aa97-ba35d95fdaa0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>province</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negros Oriental</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bohol</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Metropolitan Manila</td>\n",
       "      <td>6873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rizal</td>\n",
       "      <td>417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bulacan</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7038</th>\n",
       "      <td>Ifugao</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8321</th>\n",
       "      <td>Sulu</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8783</th>\n",
       "      <td>Guimaras</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9289</th>\n",
       "      <td>Davao Occidental</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10369</th>\n",
       "      <td>Camarines Norte</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  province  count\n",
       "0          Negros Oriental      7\n",
       "2                    Bohol      1\n",
       "3      Metropolitan Manila   6873\n",
       "4                    Rizal    417\n",
       "12                 Bulacan    141\n",
       "...                    ...    ...\n",
       "7038                Ifugao      2\n",
       "8321                  Sulu      1\n",
       "8783              Guimaras      2\n",
       "9289      Davao Occidental      1\n",
       "10369      Camarines Norte      1\n",
       "\n",
       "[61 rows x 2 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data5 = df[[\"case_id\", \"province\"]]\n",
    "data5 = data5.dropna()\n",
    "data5 = data5.reset_index(drop=True)\n",
    "data5['count'] = data5.groupby(\"province\").transform('count')\n",
    "data5.drop('case_id', inplace=True, axis=1)\n",
    "data5 = data5.drop_duplicates()\n",
    "data5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X426v2R9fWpm"
   },
   "source": [
    "Find province that has the highest case of Covid-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "XvrSGWN7-6Nn",
    "outputId": "ea406e62-44af-4263-902b-6bd28a34ad8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "province    Zamboanga del Sur\n",
       "count                    6873\n",
       "dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promax = data5.max()\n",
    "promax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HvVeT3rsfe05"
   },
   "source": [
    "Find province that has the lowest case of Covid-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "sa7PBlOr_L8m",
    "outputId": "2deadca8-6b52-4ef7-feaa-1620f6872586"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "province    Abra\n",
       "count          1\n",
       "dtype: object"
      ]
     },
     "execution_count": 84,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promin = data5.min()\n",
    "promin"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Philippines_COVID_19.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
